{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bc1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169c3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Functions \n",
    "\n",
    "def load_y_data(y_path):\n",
    "    y = np.loadtxt(y_path, dtype=np.int32).reshape(-1,1)\n",
    "    # change labels range from 1-6 t 0-5, this enables a sparse_categorical_crossentropy loss function\n",
    "    return y - 1\n",
    "\n",
    "def load_X_data(X_path):\n",
    "    X_signal_paths = [X_path + file for file in os.listdir(X_path)]\n",
    "    X_signals = [np.loadtxt(path, dtype=np.float32) for path in X_signal_paths]\n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "\n",
    "class data_set(Dataset):\n",
    "    def __init__(self, data_x, data_y):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_x = self.data_x[index]\n",
    "        sample_y = self.data_y[index]\n",
    "        return sample_x, sample_y\n",
    "    \n",
    "\n",
    "def validation(data_loader, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x,batch_y) in enumerate(data_loader):\n",
    "\n",
    "            batch_x = batch_x.double().to(device)\n",
    "            batch_y = batch_y.long().to(device)\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "\n",
    "            pred = outputs.detach()#.cpu()\n",
    "            true = batch_y.detach()#.cpu()\n",
    "\n",
    "            loss = criterion(pred, true) \n",
    "            total_loss.append(loss.cpu())\n",
    "\n",
    "            preds.extend(list(np.argmax(outputs.detach().cpu().numpy(),axis=1)))\n",
    "            trues.extend(list(batch_y.detach().cpu().numpy()))   \n",
    "\n",
    "    total_loss = np.average(total_loss)\n",
    "    acc = accuracy_score(preds,trues)\n",
    "\n",
    "    f_w = f1_score(trues, preds, average='weighted')\n",
    "    f_macro = f1_score(trues, preds, average='macro')\n",
    "    f_micro = f1_score(trues, preds, average='micro')\n",
    "    model.train()\n",
    "\n",
    "    return total_loss,  acc, f_w,  f_macro, f_micro#, f_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37641f",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d22010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful information:\n",
      "shapes (n_samples, n_steps, n_signals) of X_train: (7352, 128, 9) and X_test: (2947, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "PATH =  \"UCI HAR Dataset\"\n",
    "LABEL_NAMES = [\"Walking\", \"Walking upstairs\", \"Walking downstairs\", \"Sitting\", \"Standing\", \"Laying\"]\n",
    "\n",
    "# load X data\n",
    "X_train = load_X_data(os.path.join(PATH + r'\\train\\Inertial Signals/'))\n",
    "X_test = load_X_data(os.path.join(PATH + r'\\test\\Inertial Signals/'))\n",
    "# load y label\n",
    "y_train = load_y_data(os.path.join(PATH + r'\\train\\y_train.txt'))\n",
    "y_test = load_y_data(os.path.join(PATH + r'\\test\\y_test.txt'))\n",
    "\n",
    "print(\"useful information:\")\n",
    "print(f\"shapes (n_samples, n_steps, n_signals) of X_train: {X_train.shape} and X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e891582",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde981e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "train_data = data_set(X_train,y_train[:,0])\n",
    "test_data = data_set(X_test,y_test[:,0])\n",
    "train_data_loader = DataLoader(train_data, \n",
    "                               batch_size   =  batch_size,\n",
    "                               shuffle      =  True,\n",
    "                               num_workers  =  0,\n",
    "                               drop_last    =  False)\n",
    "\n",
    "test_data_loader = DataLoader(test_data, \n",
    "                               batch_size   =  batch_size,\n",
    "                               shuffle      =  False,\n",
    "                               num_workers  =  0,\n",
    "                               drop_last    =  False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1f63f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0175ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(ni: int, no: int, ks: int = 1, stride: int = 1, padding: int = 0, bias: bool = False):\n",
    "    \"\"\"\n",
    "    Create and initialize a `nn.Conv1d` layer with spectral normalization.\n",
    "    \"\"\"\n",
    "    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n",
    "    nn.init.kaiming_normal_(conv.weight)\n",
    "    if bias:\n",
    "        conv.bias.data.zero_()\n",
    "    # return spectral_norm(conv)\n",
    "    return conv\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    # self-attention implementation from https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "    Self attention layer for nd\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels: int, div):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        if n_channels > 1:\n",
    "            self.query = conv1d(n_channels, n_channels//div)\n",
    "            self.key = conv1d(n_channels, n_channels//div)\n",
    "        else:\n",
    "            self.query = conv1d(n_channels, n_channels)\n",
    "            self.key = conv1d(n_channels, n_channels)\n",
    "        self.value = conv1d(n_channels, n_channels)\n",
    "        self.gamma = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Notation from https://arxiv.org/pdf/1805.08318.pdf\n",
    "        size = x.size()\n",
    "        #print(\"size+\",size)\n",
    "        x = x.view(*size[:2], -1)\n",
    "        #print(\"size-\",x.size())\n",
    "        f, g, h = self.query(x), self.key(x), self.value(x)\n",
    "        beta = F.softmax(torch.bmm(f.permute(0, 2, 1).contiguous(), g), dim=1)\n",
    "        o = self.gamma * torch.bmm(h, beta) + x\n",
    "        return o.view(*size).contiguous()\n",
    "    \n",
    "class HARmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape ,\n",
    "        number_class , \n",
    "        filter_num = 32,\n",
    "        filter_size = 5,\n",
    "        nb_conv_layers = 4,\n",
    "        dropout = 0.2,\n",
    "        activation = \"ReLU\",\n",
    "        sa_div= 1,\n",
    "    ):\n",
    "        super(HARmodel, self).__init__()\n",
    "        \n",
    "        # PART 1 , Channel wise Feature Extraction\n",
    "        \n",
    "        layers_conv = []\n",
    "        for i in range(nb_conv_layers):\n",
    "        \n",
    "            if i == 0:\n",
    "                in_channel = 1\n",
    "            else:\n",
    "                in_channel = filter_num\n",
    "    \n",
    "            layers_conv.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channel, filter_num, (filter_size, 1),(2,1)),#(2,1)\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(filter_num),\n",
    "\n",
    "            ))\n",
    "        \n",
    "        self.layers_conv = nn.ModuleList(layers_conv)\n",
    "\n",
    "        # PART2 , Cross Channel Fusion through Attention\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.sa = SelfAttention(filter_num, sa_div)\n",
    "        \n",
    "        shape = self.get_the_shape(input_shape)\n",
    "\n",
    "        # PART 3 , Prediction \n",
    "        \n",
    "        self.activation = nn.ReLU() \n",
    "        self.fc1 = nn.Linear(input_shape[2]*filter_num ,filter_num)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(shape[1]*filter_num ,filter_num)\n",
    "        self.fc3 = nn.Linear(filter_num ,number_class)\n",
    "\n",
    "\n",
    "        \n",
    "    def get_the_shape(self, input_shape):\n",
    "        x = torch.rand(input_shape)\n",
    "        x = x.unsqueeze(1)\n",
    "        for layer in self.layers_conv:\n",
    "            x = layer(x)    \n",
    "        atten_x = torch.cat(\n",
    "            [self.sa(torch.unsqueeze(x[:, :, t, :], dim=3)) for t in range(x.shape[2])],\n",
    "            dim=-1,\n",
    "        )\n",
    "        atten_x = atten_x.permute(0, 3, 1, 2)\n",
    "        return atten_x.shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        # B L C\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        \n",
    "        for layer in self.layers_conv:\n",
    "            x = layer(x)      \n",
    "\n",
    "\n",
    "        batch, filter, length, channel = x.shape\n",
    "\n",
    "\n",
    "        # apply self-attention on each temporal dimension (along sensor and feature dimensions)\n",
    "        refined = torch.cat(\n",
    "            [self.sa(torch.unsqueeze(x[:, :, t, :], dim=3)) for t in range(x.shape[2])],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "\n",
    "       # print(refined.shape)\n",
    "\n",
    "        x = refined.permute(0, 3, 1, 2)\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.activation(self.fc1(x)) # B L C\n",
    "        x = self.flatten(x)\n",
    "        x = self.activation(self.fc2(x)) # B L C\n",
    "        y = self.fc3(x)    \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988c8bb",
   "metadata": {},
   "source": [
    "# Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39437a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter : 8599\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import time\n",
    "learning_rate = 0.0001\n",
    "train_epochs = 300\n",
    "device = torch.device('cuda:{}'.format(0))\n",
    "criterion =  nn.CrossEntropyLoss(reduction=\"mean\").to(device)\n",
    "\n",
    "\n",
    "#input_shape = (1, length, channel)\n",
    "model = HARmodel((1,128,9),6,filter_num = 16).double().to(device)\n",
    "\n",
    "print(\"Parameter :\", np.sum([para.numel() for para in model.parameters()]))\n",
    "model_optim = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_steps = len(train_data_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58137fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost time: 2.579564332962036\n",
      "TEST: Epoch: 1, Steps: 58 | Train Loss: 1.7799829  Test Loss: 1.7580593 Test Accuracy: 0.1849338  Test weighted F1: 0.0644454  Test macro F1 0.0604943 \n",
      "Epoch: 2 cost time: 0.8361878395080566\n",
      "TEST: Epoch: 2, Steps: 58 | Train Loss: 1.7135453  Test Loss: 1.6462650 Test Accuracy: 0.3552766  Test weighted F1: 0.3115916  Test macro F1 0.3019697 \n",
      "Epoch: 3 cost time: 0.8311865329742432\n",
      "TEST: Epoch: 3, Steps: 58 | Train Loss: 1.5371445  Test Loss: 1.4146416 Test Accuracy: 0.5252799  Test weighted F1: 0.4287501  Test macro F1 0.4059433 \n",
      "Epoch: 4 cost time: 0.8201849460601807\n",
      "TEST: Epoch: 4, Steps: 58 | Train Loss: 1.2758150  Test Loss: 1.1655750 Test Accuracy: 0.5531049  Test weighted F1: 0.4506928  Test macro F1 0.4263962 \n",
      "Epoch: 5 cost time: 0.8228397369384766\n",
      "TEST: Epoch: 5, Steps: 58 | Train Loss: 1.0478701  Test Loss: 0.9738914 Test Accuracy: 0.6131659  Test weighted F1: 0.5475272  Test macro F1 0.5247185 \n",
      "Epoch: 6 cost time: 0.8237569332122803\n",
      "TEST: Epoch: 6, Steps: 58 | Train Loss: 0.8767629  Test Loss: 0.8281813 Test Accuracy: 0.6756023  Test weighted F1: 0.6400795  Test macro F1 0.6208090 \n",
      "Epoch: 7 cost time: 0.8391892910003662\n",
      "TEST: Epoch: 7, Steps: 58 | Train Loss: 0.7569774  Test Loss: 0.7335373 Test Accuracy: 0.7163217  Test weighted F1: 0.7005341  Test macro F1 0.6859910 \n",
      "Epoch: 8 cost time: 0.8331882953643799\n",
      "TEST: Epoch: 8, Steps: 58 | Train Loss: 0.6724496  Test Loss: 0.6457013 Test Accuracy: 0.7366814  Test weighted F1: 0.7216843  Test macro F1 0.7081210 \n",
      "Epoch: 9 cost time: 0.835188627243042\n",
      "TEST: Epoch: 9, Steps: 58 | Train Loss: 0.6031004  Test Loss: 0.5989482 Test Accuracy: 0.7675602  Test weighted F1: 0.7601215  Test macro F1 0.7498597 \n",
      "Epoch: 10 cost time: 0.825186014175415\n",
      "TEST: Epoch: 10, Steps: 58 | Train Loss: 0.5361910  Test Loss: 0.5369894 Test Accuracy: 0.7862233  Test weighted F1: 0.7821389  Test macro F1 0.7739673 \n",
      "Epoch: 11 cost time: 0.827185869216919\n",
      "TEST: Epoch: 11, Steps: 58 | Train Loss: 0.4774347  Test Loss: 0.4670134 Test Accuracy: 0.8194774  Test weighted F1: 0.8166014  Test macro F1 0.8101972 \n",
      "Epoch: 12 cost time: 0.8421883583068848\n",
      "TEST: Epoch: 12, Steps: 58 | Train Loss: 0.4118733  Test Loss: 0.4129300 Test Accuracy: 0.8381405  Test weighted F1: 0.8360001  Test macro F1 0.8313271 \n",
      "Epoch: 13 cost time: 0.8341879844665527\n",
      "TEST: Epoch: 13, Steps: 58 | Train Loss: 0.3499734  Test Loss: 0.3638316 Test Accuracy: 0.8483203  Test weighted F1: 0.8471958  Test macro F1 0.8442671 \n",
      "Epoch: 14 cost time: 0.8401894569396973\n",
      "TEST: Epoch: 14, Steps: 58 | Train Loss: 0.2963864  Test Loss: 0.3234889 Test Accuracy: 0.8625721  Test weighted F1: 0.8620133  Test macro F1 0.8596462 \n",
      "Epoch: 15 cost time: 0.8261849880218506\n",
      "TEST: Epoch: 15, Steps: 58 | Train Loss: 0.2651126  Test Loss: 0.3003767 Test Accuracy: 0.8652867  Test weighted F1: 0.8644243  Test macro F1 0.8626679 \n",
      "Epoch: 16 cost time: 0.8311882019042969\n",
      "TEST: Epoch: 16, Steps: 58 | Train Loss: 0.2372900  Test Loss: 0.2808477 Test Accuracy: 0.8771632  Test weighted F1: 0.8766458  Test macro F1 0.8748458 \n",
      "Epoch: 17 cost time: 0.8281867504119873\n",
      "TEST: Epoch: 17, Steps: 58 | Train Loss: 0.2165753  Test Loss: 0.2638086 Test Accuracy: 0.8927723  Test weighted F1: 0.8921631  Test macro F1 0.8902107 \n",
      "Epoch: 18 cost time: 0.8581933975219727\n",
      "TEST: Epoch: 18, Steps: 58 | Train Loss: 0.2008707  Test Loss: 0.2555288 Test Accuracy: 0.8890397  Test weighted F1: 0.8886519  Test macro F1 0.8870962 \n",
      "Epoch: 19 cost time: 0.8331873416900635\n",
      "TEST: Epoch: 19, Steps: 58 | Train Loss: 0.1879118  Test Loss: 0.2406876 Test Accuracy: 0.8958263  Test weighted F1: 0.8955131  Test macro F1 0.8940363 \n",
      "Epoch: 20 cost time: 0.835188627243042\n",
      "TEST: Epoch: 20, Steps: 58 | Train Loss: 0.1769278  Test Loss: 0.2303751 Test Accuracy: 0.8941296  Test weighted F1: 0.8939411  Test macro F1 0.8931373 \n",
      "Epoch: 21 cost time: 0.8301877975463867\n",
      "TEST: Epoch: 21, Steps: 58 | Train Loss: 0.1674779  Test Loss: 0.2294035 Test Accuracy: 0.8998982  Test weighted F1: 0.8994303  Test macro F1 0.8978877 \n",
      "Epoch: 22 cost time: 0.838188886642456\n",
      "TEST: Epoch: 22, Steps: 58 | Train Loss: 0.1597538  Test Loss: 0.2209079 Test Accuracy: 0.9029522  Test weighted F1: 0.9025545  Test macro F1 0.9012184 \n",
      "Epoch: 23 cost time: 0.8341884613037109\n",
      "TEST: Epoch: 23, Steps: 58 | Train Loss: 0.1537576  Test Loss: 0.2037636 Test Accuracy: 0.9134713  Test weighted F1: 0.9132413  Test macro F1 0.9122740 \n",
      "Epoch: 24 cost time: 0.8331880569458008\n",
      "TEST: Epoch: 24, Steps: 58 | Train Loss: 0.1539155  Test Loss: 0.2183170 Test Accuracy: 0.9039701  Test weighted F1: 0.9037983  Test macro F1 0.9028092 \n",
      "Epoch: 25 cost time: 0.8411910533905029\n",
      "TEST: Epoch: 25, Steps: 58 | Train Loss: 0.1465735  Test Loss: 0.2048387 Test Accuracy: 0.9100780  Test weighted F1: 0.9099487  Test macro F1 0.9092032 \n",
      "Epoch: 26 cost time: 0.8347525596618652\n",
      "TEST: Epoch: 26, Steps: 58 | Train Loss: 0.1435325  Test Loss: 0.2027639 Test Accuracy: 0.9124533  Test weighted F1: 0.9122138  Test macro F1 0.9114347 \n",
      "Epoch: 27 cost time: 0.8351879119873047\n",
      "TEST: Epoch: 27, Steps: 58 | Train Loss: 0.1388999  Test Loss: 0.2043354 Test Accuracy: 0.9100780  Test weighted F1: 0.9098240  Test macro F1 0.9089737 \n",
      "Epoch: 28 cost time: 0.8358800411224365\n",
      "TEST: Epoch: 28, Steps: 58 | Train Loss: 0.1312283  Test Loss: 0.2057755 Test Accuracy: 0.9093994  Test weighted F1: 0.9091376  Test macro F1 0.9083417 \n",
      "Epoch: 29 cost time: 0.8541927337646484\n",
      "TEST: Epoch: 29, Steps: 58 | Train Loss: 0.1285332  Test Loss: 0.1901324 Test Accuracy: 0.9199186  Test weighted F1: 0.9198550  Test macro F1 0.9193644 \n",
      "Epoch: 30 cost time: 0.8351881504058838\n",
      "TEST: Epoch: 30, Steps: 58 | Train Loss: 0.1261258  Test Loss: 0.1925043 Test Accuracy: 0.9219545  Test weighted F1: 0.9217320  Test macro F1 0.9209525 \n",
      "Epoch: 31 cost time: 0.8351881504058838\n",
      "TEST: Epoch: 31, Steps: 58 | Train Loss: 0.1195548  Test Loss: 0.1921054 Test Accuracy: 0.9175433  Test weighted F1: 0.9172868  Test macro F1 0.9166904 \n",
      "Epoch: 32 cost time: 0.8270184993743896\n",
      "TEST: Epoch: 32, Steps: 58 | Train Loss: 0.1188192  Test Loss: 0.1901654 Test Accuracy: 0.9155073  Test weighted F1: 0.9153839  Test macro F1 0.9148816 \n",
      "Epoch: 33 cost time: 0.8277714252471924\n",
      "TEST: Epoch: 33, Steps: 58 | Train Loss: 0.1173253  Test Loss: 0.1901250 Test Accuracy: 0.9226332  Test weighted F1: 0.9224084  Test macro F1 0.9216251 \n",
      "Epoch: 34 cost time: 0.8266587257385254\n",
      "TEST: Epoch: 34, Steps: 58 | Train Loss: 0.1134378  Test Loss: 0.1840332 Test Accuracy: 0.9229725  Test weighted F1: 0.9229226  Test macro F1 0.9226790 \n",
      "Epoch: 35 cost time: 0.8331875801086426\n",
      "TEST: Epoch: 35, Steps: 58 | Train Loss: 0.1176898  Test Loss: 0.1849365 Test Accuracy: 0.9233118  Test weighted F1: 0.9232301  Test macro F1 0.9231384 \n",
      "Epoch: 36 cost time: 0.8471906185150146\n",
      "TEST: Epoch: 36, Steps: 58 | Train Loss: 0.1115631  Test Loss: 0.1902753 Test Accuracy: 0.9212759  Test weighted F1: 0.9209969  Test macro F1 0.9203776 \n",
      "Epoch: 37 cost time: 0.848191499710083\n",
      "TEST: Epoch: 37, Steps: 58 | Train Loss: 0.1109783  Test Loss: 0.1911285 Test Accuracy: 0.9189006  Test weighted F1: 0.9187752  Test macro F1 0.9186558 \n",
      "Epoch: 38 cost time: 0.8771967887878418\n",
      "TEST: Epoch: 38, Steps: 58 | Train Loss: 0.1106484  Test Loss: 0.1829906 Test Accuracy: 0.9222939  Test weighted F1: 0.9222030  Test macro F1 0.9218161 \n",
      "Epoch: 39 cost time: 0.8461904525756836\n",
      "TEST: Epoch: 39, Steps: 58 | Train Loss: 0.1093638  Test Loss: 0.1859903 Test Accuracy: 0.9236512  Test weighted F1: 0.9235482  Test macro F1 0.9234904 \n",
      "Epoch: 40 cost time: 0.8441908359527588\n",
      "TEST: Epoch: 40, Steps: 58 | Train Loss: 0.1107840  Test Loss: 0.1872215 Test Accuracy: 0.9219545  Test weighted F1: 0.9219381  Test macro F1 0.9216295 \n",
      "Epoch: 41 cost time: 0.8431897163391113\n",
      "TEST: Epoch: 41, Steps: 58 | Train Loss: 0.1061336  Test Loss: 0.1833504 Test Accuracy: 0.9270445  Test weighted F1: 0.9268444  Test macro F1 0.9264846 \n",
      "Epoch: 42 cost time: 0.844191312789917\n",
      "TEST: Epoch: 42, Steps: 58 | Train Loss: 0.1025417  Test Loss: 0.1739405 Test Accuracy: 0.9321344  Test weighted F1: 0.9321151  Test macro F1 0.9322697 \n",
      "Epoch: 43 cost time: 0.843189001083374\n",
      "TEST: Epoch: 43, Steps: 58 | Train Loss: 0.1029196  Test Loss: 0.1765407 Test Accuracy: 0.9256871  Test weighted F1: 0.9256457  Test macro F1 0.9257120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 cost time: 0.8451900482177734\n",
      "TEST: Epoch: 44, Steps: 58 | Train Loss: 0.1010345  Test Loss: 0.1797777 Test Accuracy: 0.9277231  Test weighted F1: 0.9275828  Test macro F1 0.9275283 \n",
      "Epoch: 45 cost time: 0.8371884822845459\n",
      "TEST: Epoch: 45, Steps: 58 | Train Loss: 0.0982539  Test Loss: 0.1713655 Test Accuracy: 0.9307771  Test weighted F1: 0.9306995  Test macro F1 0.9309815 \n",
      "Epoch: 46 cost time: 0.8401885032653809\n",
      "TEST: Epoch: 46, Steps: 58 | Train Loss: 0.0984123  Test Loss: 0.1796018 Test Accuracy: 0.9331524  Test weighted F1: 0.9329090  Test macro F1 0.9330310 \n",
      "Epoch: 47 cost time: 0.8471920490264893\n",
      "TEST: Epoch: 47, Steps: 58 | Train Loss: 0.0975804  Test Loss: 0.1774907 Test Accuracy: 0.9338310  Test weighted F1: 0.9336377  Test macro F1 0.9338634 \n",
      "Epoch: 48 cost time: 0.8291864395141602\n",
      "TEST: Epoch: 48, Steps: 58 | Train Loss: 0.0943914  Test Loss: 0.1804899 Test Accuracy: 0.9307771  Test weighted F1: 0.9305658  Test macro F1 0.9307351 \n",
      "Epoch: 49 cost time: 0.8401892185211182\n",
      "TEST: Epoch: 49, Steps: 58 | Train Loss: 0.0939031  Test Loss: 0.1834298 Test Accuracy: 0.9287411  Test weighted F1: 0.9284880  Test macro F1 0.9290126 \n",
      "Epoch: 50 cost time: 0.8351888656616211\n",
      "TEST: Epoch: 50, Steps: 58 | Train Loss: 0.0921124  Test Loss: 0.1692332 Test Accuracy: 0.9351883  Test weighted F1: 0.9351141  Test macro F1 0.9356495 \n",
      "Epoch: 51 cost time: 0.8391890525817871\n",
      "TEST: Epoch: 51, Steps: 58 | Train Loss: 0.0888950  Test Loss: 0.1699464 Test Accuracy: 0.9345097  Test weighted F1: 0.9343897  Test macro F1 0.9351469 \n",
      "Epoch: 52 cost time: 0.8641948699951172\n",
      "TEST: Epoch: 52, Steps: 58 | Train Loss: 0.0905443  Test Loss: 0.1763723 Test Accuracy: 0.9324737  Test weighted F1: 0.9323923  Test macro F1 0.9325637 \n",
      "Epoch: 53 cost time: 0.8548886775970459\n",
      "TEST: Epoch: 53, Steps: 58 | Train Loss: 0.0871552  Test Loss: 0.1776101 Test Accuracy: 0.9314557  Test weighted F1: 0.9312445  Test macro F1 0.9315976 \n",
      "Epoch: 54 cost time: 0.8341877460479736\n",
      "TEST: Epoch: 54, Steps: 58 | Train Loss: 0.0877289  Test Loss: 0.1652712 Test Accuracy: 0.9348490  Test weighted F1: 0.9347488  Test macro F1 0.9350057 \n",
      "Epoch: 55 cost time: 0.8346810340881348\n",
      "TEST: Epoch: 55, Steps: 58 | Train Loss: 0.0847947  Test Loss: 0.1715303 Test Accuracy: 0.9304377  Test weighted F1: 0.9303422  Test macro F1 0.9307661 \n",
      "Epoch: 56 cost time: 0.8361892700195312\n",
      "TEST: Epoch: 56, Steps: 58 | Train Loss: 0.0884222  Test Loss: 0.1772729 Test Accuracy: 0.9300984  Test weighted F1: 0.9299667  Test macro F1 0.9304211 \n",
      "Epoch: 57 cost time: 0.8451910018920898\n",
      "TEST: Epoch: 57, Steps: 58 | Train Loss: 0.0817995  Test Loss: 0.1687532 Test Accuracy: 0.9321344  Test weighted F1: 0.9320048  Test macro F1 0.9322948 \n",
      "Epoch: 58 cost time: 0.8411900997161865\n",
      "TEST: Epoch: 58, Steps: 58 | Train Loss: 0.0832042  Test Loss: 0.1720649 Test Accuracy: 0.9297591  Test weighted F1: 0.9296843  Test macro F1 0.9299507 \n",
      "Epoch: 59 cost time: 0.8427064418792725\n",
      "TEST: Epoch: 59, Steps: 58 | Train Loss: 0.0806595  Test Loss: 0.1834526 Test Accuracy: 0.9267051  Test weighted F1: 0.9264499  Test macro F1 0.9269820 \n",
      "Epoch: 60 cost time: 0.839188814163208\n",
      "TEST: Epoch: 60, Steps: 58 | Train Loss: 0.0797911  Test Loss: 0.1690654 Test Accuracy: 0.9331524  Test weighted F1: 0.9330564  Test macro F1 0.9335813 \n",
      "Epoch: 61 cost time: 0.8491916656494141\n",
      "TEST: Epoch: 61, Steps: 58 | Train Loss: 0.0807557  Test Loss: 0.1658706 Test Accuracy: 0.9348490  Test weighted F1: 0.9347644  Test macro F1 0.9352916 \n",
      "Epoch: 62 cost time: 0.8411898612976074\n",
      "TEST: Epoch: 62, Steps: 58 | Train Loss: 0.0786345  Test Loss: 0.1790914 Test Accuracy: 0.9270445  Test weighted F1: 0.9269227  Test macro F1 0.9274438 \n",
      "Epoch: 63 cost time: 0.8721959590911865\n",
      "TEST: Epoch: 63, Steps: 58 | Train Loss: 0.0806451  Test Loss: 0.1691794 Test Accuracy: 0.9311164  Test weighted F1: 0.9310686  Test macro F1 0.9316962 \n",
      "Epoch: 64 cost time: 0.8571939468383789\n",
      "TEST: Epoch: 64, Steps: 58 | Train Loss: 0.0754110  Test Loss: 0.1681654 Test Accuracy: 0.9341703  Test weighted F1: 0.9341022  Test macro F1 0.9348973 \n",
      "Epoch: 65 cost time: 0.8785738945007324\n",
      "TEST: Epoch: 65, Steps: 58 | Train Loss: 0.0726071  Test Loss: 0.1682772 Test Accuracy: 0.9348490  Test weighted F1: 0.9347859  Test macro F1 0.9353980 \n",
      "Epoch: 66 cost time: 0.8828022480010986\n",
      "TEST: Epoch: 66, Steps: 58 | Train Loss: 0.0754569  Test Loss: 0.1764442 Test Accuracy: 0.9311164  Test weighted F1: 0.9309560  Test macro F1 0.9315695 \n",
      "Epoch: 67 cost time: 0.9107468128204346\n",
      "TEST: Epoch: 67, Steps: 58 | Train Loss: 0.0701496  Test Loss: 0.1647049 Test Accuracy: 0.9345097  Test weighted F1: 0.9344627  Test macro F1 0.9352027 \n",
      "Epoch: 68 cost time: 0.9174239635467529\n",
      "TEST: Epoch: 68, Steps: 58 | Train Loss: 0.0705300  Test Loss: 0.1713103 Test Accuracy: 0.9260265  Test weighted F1: 0.9258709  Test macro F1 0.9269690 \n",
      "Epoch: 69 cost time: 0.8855102062225342\n",
      "TEST: Epoch: 69, Steps: 58 | Train Loss: 0.0705284  Test Loss: 0.1669255 Test Accuracy: 0.9304377  Test weighted F1: 0.9302791  Test macro F1 0.9311386 \n",
      "Epoch: 70 cost time: 0.892827033996582\n",
      "TEST: Epoch: 70, Steps: 58 | Train Loss: 0.0713978  Test Loss: 0.1704415 Test Accuracy: 0.9334917  Test weighted F1: 0.9334266  Test macro F1 0.9338898 \n",
      "Epoch: 71 cost time: 0.874197244644165\n",
      "TEST: Epoch: 71, Steps: 58 | Train Loss: 0.0674667  Test Loss: 0.1724604 Test Accuracy: 0.9314557  Test weighted F1: 0.9313305  Test macro F1 0.9321798 \n",
      "Epoch: 72 cost time: 0.8591938018798828\n",
      "TEST: Epoch: 72, Steps: 58 | Train Loss: 0.0669321  Test Loss: 0.1631283 Test Accuracy: 0.9362063  Test weighted F1: 0.9361372  Test macro F1 0.9368555 \n",
      "Epoch: 73 cost time: 0.8721466064453125\n",
      "TEST: Epoch: 73, Steps: 58 | Train Loss: 0.0637160  Test Loss: 0.1654026 Test Accuracy: 0.9355277  Test weighted F1: 0.9354302  Test macro F1 0.9363904 \n",
      "Epoch: 74 cost time: 0.8851659297943115\n",
      "TEST: Epoch: 74, Steps: 58 | Train Loss: 0.0640742  Test Loss: 0.1681537 Test Accuracy: 0.9297591  Test weighted F1: 0.9295914  Test macro F1 0.9305234 \n",
      "Epoch: 75 cost time: 0.8724076747894287\n",
      "TEST: Epoch: 75, Steps: 58 | Train Loss: 0.0638739  Test Loss: 0.1720413 Test Accuracy: 0.9338310  Test weighted F1: 0.9336875  Test macro F1 0.9341814 \n",
      "Epoch: 76 cost time: 0.8826959133148193\n",
      "TEST: Epoch: 76, Steps: 58 | Train Loss: 0.0641500  Test Loss: 0.1638149 Test Accuracy: 0.9392603  Test weighted F1: 0.9391416  Test macro F1 0.9395631 \n",
      "Epoch: 77 cost time: 0.8738877773284912\n",
      "TEST: Epoch: 77, Steps: 58 | Train Loss: 0.0633312  Test Loss: 0.1676804 Test Accuracy: 0.9341703  Test weighted F1: 0.9339994  Test macro F1 0.9348814 \n",
      "Epoch: 78 cost time: 0.8773167133331299\n",
      "TEST: Epoch: 78, Steps: 58 | Train Loss: 0.0612879  Test Loss: 0.1766618 Test Accuracy: 0.9314557  Test weighted F1: 0.9312978  Test macro F1 0.9322395 \n",
      "Epoch: 79 cost time: 0.8762407302856445\n",
      "TEST: Epoch: 79, Steps: 58 | Train Loss: 0.0627411  Test Loss: 0.1899411 Test Accuracy: 0.9273838  Test weighted F1: 0.9271502  Test macro F1 0.9277439 \n",
      "Epoch: 80 cost time: 0.8657238483428955\n",
      "TEST: Epoch: 80, Steps: 58 | Train Loss: 0.0632108  Test Loss: 0.1652022 Test Accuracy: 0.9375636  Test weighted F1: 0.9375529  Test macro F1 0.9384252 \n",
      "Epoch: 81 cost time: 0.9121673107147217\n",
      "TEST: Epoch: 81, Steps: 58 | Train Loss: 0.0615015  Test Loss: 0.1613644 Test Accuracy: 0.9379030  Test weighted F1: 0.9378636  Test macro F1 0.9387819 \n",
      "Epoch: 82 cost time: 0.9111082553863525\n",
      "TEST: Epoch: 82, Steps: 58 | Train Loss: 0.0639794  Test Loss: 0.1707767 Test Accuracy: 0.9287411  Test weighted F1: 0.9286723  Test macro F1 0.9298654 \n",
      "Epoch: 83 cost time: 0.9000208377838135\n",
      "TEST: Epoch: 83, Steps: 58 | Train Loss: 0.0619152  Test Loss: 0.1707733 Test Accuracy: 0.9348490  Test weighted F1: 0.9346805  Test macro F1 0.9355645 \n",
      "Epoch: 84 cost time: 0.8968515396118164\n",
      "TEST: Epoch: 84, Steps: 58 | Train Loss: 0.0582923  Test Loss: 0.1735351 Test Accuracy: 0.9307771  Test weighted F1: 0.9307389  Test macro F1 0.9318399 \n",
      "Epoch: 85 cost time: 0.890181303024292\n",
      "TEST: Epoch: 85, Steps: 58 | Train Loss: 0.0586588  Test Loss: 0.1800505 Test Accuracy: 0.9270445  Test weighted F1: 0.9267574  Test macro F1 0.9276200 \n",
      "Epoch: 86 cost time: 0.8521914482116699\n",
      "TEST: Epoch: 86, Steps: 58 | Train Loss: 0.0566754  Test Loss: 0.1992260 Test Accuracy: 0.9239905  Test weighted F1: 0.9237443  Test macro F1 0.9243554 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87 cost time: 0.8571934700012207\n",
      "TEST: Epoch: 87, Steps: 58 | Train Loss: 0.0555979  Test Loss: 0.1640245 Test Accuracy: 0.9392603  Test weighted F1: 0.9391115  Test macro F1 0.9399048 \n",
      "Epoch: 88 cost time: 0.8511910438537598\n",
      "TEST: Epoch: 88, Steps: 58 | Train Loss: 0.0574336  Test Loss: 0.1723937 Test Accuracy: 0.9297591  Test weighted F1: 0.9295496  Test macro F1 0.9302209 \n",
      "Epoch: 89 cost time: 0.852191686630249\n",
      "TEST: Epoch: 89, Steps: 58 | Train Loss: 0.0599803  Test Loss: 0.1850674 Test Accuracy: 0.9277231  Test weighted F1: 0.9274660  Test macro F1 0.9278984 \n",
      "Epoch: 90 cost time: 0.8865878582000732\n",
      "TEST: Epoch: 90, Steps: 58 | Train Loss: 0.0546199  Test Loss: 0.1643269 Test Accuracy: 0.9362063  Test weighted F1: 0.9361376  Test macro F1 0.9371596 \n",
      "Epoch: 91 cost time: 0.8919456005096436\n",
      "TEST: Epoch: 91, Steps: 58 | Train Loss: 0.0562203  Test Loss: 0.1664831 Test Accuracy: 0.9358670  Test weighted F1: 0.9357485  Test macro F1 0.9363790 \n",
      "Epoch: 92 cost time: 0.8743672370910645\n",
      "TEST: Epoch: 92, Steps: 58 | Train Loss: 0.0500874  Test Loss: 0.1742036 Test Accuracy: 0.9345097  Test weighted F1: 0.9343958  Test macro F1 0.9351974 \n",
      "Epoch: 93 cost time: 0.8560342788696289\n",
      "TEST: Epoch: 93, Steps: 58 | Train Loss: 0.0526131  Test Loss: 0.1880358 Test Accuracy: 0.9334917  Test weighted F1: 0.9332308  Test macro F1 0.9335536 \n",
      "Epoch: 94 cost time: 0.8591947555541992\n",
      "TEST: Epoch: 94, Steps: 58 | Train Loss: 0.0612824  Test Loss: 0.1747902 Test Accuracy: 0.9311164  Test weighted F1: 0.9309298  Test macro F1 0.9318625 \n",
      "Epoch: 95 cost time: 0.8976380825042725\n",
      "TEST: Epoch: 95, Steps: 58 | Train Loss: 0.0549980  Test Loss: 0.1652785 Test Accuracy: 0.9368850  Test weighted F1: 0.9367895  Test macro F1 0.9376113 \n",
      "Epoch: 96 cost time: 0.8895208835601807\n",
      "TEST: Epoch: 96, Steps: 58 | Train Loss: 0.0541744  Test Loss: 0.1946807 Test Accuracy: 0.9229725  Test weighted F1: 0.9227941  Test macro F1 0.9236784 \n",
      "Epoch: 97 cost time: 0.897512674331665\n",
      "TEST: Epoch: 97, Steps: 58 | Train Loss: 0.0494339  Test Loss: 0.1772791 Test Accuracy: 0.9300984  Test weighted F1: 0.9299918  Test macro F1 0.9308314 \n",
      "Epoch: 98 cost time: 0.9006960391998291\n",
      "TEST: Epoch: 98, Steps: 58 | Train Loss: 0.0536037  Test Loss: 0.1544733 Test Accuracy: 0.9402782  Test weighted F1: 0.9401618  Test macro F1 0.9406579 \n",
      "Epoch: 99 cost time: 0.9017035961151123\n",
      "TEST: Epoch: 99, Steps: 58 | Train Loss: 0.0491801  Test Loss: 0.1649715 Test Accuracy: 0.9341703  Test weighted F1: 0.9340794  Test macro F1 0.9349917 \n",
      "Epoch: 100 cost time: 0.8854641914367676\n",
      "TEST: Epoch: 100, Steps: 58 | Train Loss: 0.0458525  Test Loss: 0.1757319 Test Accuracy: 0.9304377  Test weighted F1: 0.9303254  Test macro F1 0.9312747 \n",
      "Epoch: 101 cost time: 0.8816838264465332\n",
      "TEST: Epoch: 101, Steps: 58 | Train Loss: 0.0472717  Test Loss: 0.1784150 Test Accuracy: 0.9317950  Test weighted F1: 0.9316506  Test macro F1 0.9325865 \n",
      "Epoch: 102 cost time: 0.8773431777954102\n",
      "TEST: Epoch: 102, Steps: 58 | Train Loss: 0.0532549  Test Loss: 0.1862768 Test Accuracy: 0.9236512  Test weighted F1: 0.9234733  Test macro F1 0.9249040 \n",
      "Epoch: 103 cost time: 0.8984217643737793\n",
      "TEST: Epoch: 103, Steps: 58 | Train Loss: 0.0472033  Test Loss: 0.1843525 Test Accuracy: 0.9246692  Test weighted F1: 0.9244926  Test macro F1 0.9255620 \n",
      "Epoch: 104 cost time: 0.9115452766418457\n",
      "TEST: Epoch: 104, Steps: 58 | Train Loss: 0.0478657  Test Loss: 0.1765106 Test Accuracy: 0.9294197  Test weighted F1: 0.9293332  Test macro F1 0.9302099 \n",
      "Epoch: 105 cost time: 0.9222071170806885\n",
      "TEST: Epoch: 105, Steps: 58 | Train Loss: 0.0453895  Test Loss: 0.1968657 Test Accuracy: 0.9233118  Test weighted F1: 0.9231890  Test macro F1 0.9243528 \n",
      "Epoch: 106 cost time: 0.8927633762359619\n",
      "TEST: Epoch: 106, Steps: 58 | Train Loss: 0.0445524  Test Loss: 0.1879904 Test Accuracy: 0.9273838  Test weighted F1: 0.9272491  Test macro F1 0.9283409 \n",
      "Epoch: 107 cost time: 0.8923225402832031\n",
      "TEST: Epoch: 107, Steps: 58 | Train Loss: 0.0476967  Test Loss: 0.1758136 Test Accuracy: 0.9300984  Test weighted F1: 0.9300501  Test macro F1 0.9312713 \n",
      "Epoch: 108 cost time: 0.8762538433074951\n",
      "TEST: Epoch: 108, Steps: 58 | Train Loss: 0.0485929  Test Loss: 0.1753475 Test Accuracy: 0.9287411  Test weighted F1: 0.9286152  Test macro F1 0.9296600 \n",
      "Epoch: 109 cost time: 0.8817529678344727\n",
      "TEST: Epoch: 109, Steps: 58 | Train Loss: 0.0454178  Test Loss: 0.1767100 Test Accuracy: 0.9321344  Test weighted F1: 0.9320651  Test macro F1 0.9330923 \n",
      "Epoch: 110 cost time: 0.9099969863891602\n",
      "TEST: Epoch: 110, Steps: 58 | Train Loss: 0.0466254  Test Loss: 0.1716169 Test Accuracy: 0.9338310  Test weighted F1: 0.9336903  Test macro F1 0.9344962 \n",
      "Epoch: 111 cost time: 0.9104466438293457\n",
      "TEST: Epoch: 111, Steps: 58 | Train Loss: 0.0464756  Test Loss: 0.1875808 Test Accuracy: 0.9236512  Test weighted F1: 0.9234713  Test macro F1 0.9242582 \n",
      "Epoch: 112 cost time: 0.8754363059997559\n",
      "TEST: Epoch: 112, Steps: 58 | Train Loss: 0.0438332  Test Loss: 0.1904906 Test Accuracy: 0.9334917  Test weighted F1: 0.9332294  Test macro F1 0.9336968 \n",
      "Epoch: 113 cost time: 0.883765459060669\n",
      "TEST: Epoch: 113, Steps: 58 | Train Loss: 0.0418452  Test Loss: 0.1777673 Test Accuracy: 0.9317950  Test weighted F1: 0.9316359  Test macro F1 0.9325156 \n",
      "Epoch: 114 cost time: 0.8809332847595215\n",
      "TEST: Epoch: 114, Steps: 58 | Train Loss: 0.0428909  Test Loss: 0.1737913 Test Accuracy: 0.9368850  Test weighted F1: 0.9367964  Test macro F1 0.9377969 \n",
      "Epoch: 115 cost time: 0.8843767642974854\n",
      "TEST: Epoch: 115, Steps: 58 | Train Loss: 0.0418047  Test Loss: 0.1720670 Test Accuracy: 0.9385816  Test weighted F1: 0.9385441  Test macro F1 0.9395563 \n",
      "Epoch: 116 cost time: 0.892812967300415\n",
      "TEST: Epoch: 116, Steps: 58 | Train Loss: 0.0433250  Test Loss: 0.1808098 Test Accuracy: 0.9300984  Test weighted F1: 0.9300151  Test macro F1 0.9311366 \n",
      "Epoch: 117 cost time: 0.8888144493103027\n",
      "TEST: Epoch: 117, Steps: 58 | Train Loss: 0.0426585  Test Loss: 0.1896332 Test Accuracy: 0.9287411  Test weighted F1: 0.9286185  Test macro F1 0.9293293 \n",
      "Epoch: 118 cost time: 0.9177186489105225\n",
      "TEST: Epoch: 118, Steps: 58 | Train Loss: 0.0425555  Test Loss: 0.1801375 Test Accuracy: 0.9351883  Test weighted F1: 0.9350936  Test macro F1 0.9361515 \n",
      "Epoch: 119 cost time: 0.9063472747802734\n",
      "TEST: Epoch: 119, Steps: 58 | Train Loss: 0.0394586  Test Loss: 0.1823226 Test Accuracy: 0.9351883  Test weighted F1: 0.9350172  Test macro F1 0.9357704 \n",
      "Epoch: 120 cost time: 0.9075624942779541\n",
      "TEST: Epoch: 120, Steps: 58 | Train Loss: 0.0384920  Test Loss: 0.1920412 Test Accuracy: 0.9277231  Test weighted F1: 0.9275037  Test macro F1 0.9286441 \n",
      "Epoch: 121 cost time: 0.9124178886413574\n",
      "TEST: Epoch: 121, Steps: 58 | Train Loss: 0.0391513  Test Loss: 0.1910228 Test Accuracy: 0.9311164  Test weighted F1: 0.9308959  Test macro F1 0.9316063 \n",
      "Epoch: 122 cost time: 0.9160032272338867\n",
      "TEST: Epoch: 122, Steps: 58 | Train Loss: 0.0422599  Test Loss: 0.1685575 Test Accuracy: 0.9395996  Test weighted F1: 0.9394343  Test macro F1 0.9399062 \n",
      "Epoch: 123 cost time: 0.9146971702575684\n",
      "TEST: Epoch: 123, Steps: 58 | Train Loss: 0.0403579  Test Loss: 0.2012185 Test Accuracy: 0.9246692  Test weighted F1: 0.9244950  Test macro F1 0.9253810 \n",
      "Epoch: 124 cost time: 0.9050729274749756\n",
      "TEST: Epoch: 124, Steps: 58 | Train Loss: 0.0381555  Test Loss: 0.1923949 Test Accuracy: 0.9246692  Test weighted F1: 0.9245446  Test macro F1 0.9253181 \n",
      "Epoch: 125 cost time: 0.9140653610229492\n",
      "TEST: Epoch: 125, Steps: 58 | Train Loss: 0.0403521  Test Loss: 0.1740892 Test Accuracy: 0.9355277  Test weighted F1: 0.9353965  Test macro F1 0.9358292 \n",
      "Epoch: 126 cost time: 0.9028830528259277\n",
      "TEST: Epoch: 126, Steps: 58 | Train Loss: 0.0380694  Test Loss: 0.1733539 Test Accuracy: 0.9399389  Test weighted F1: 0.9396733  Test macro F1 0.9401036 \n",
      "Epoch: 127 cost time: 0.8854565620422363\n",
      "TEST: Epoch: 127, Steps: 58 | Train Loss: 0.0374839  Test Loss: 0.1779751 Test Accuracy: 0.9334917  Test weighted F1: 0.9333617  Test macro F1 0.9341280 \n",
      "Epoch: 128 cost time: 0.8810398578643799\n",
      "TEST: Epoch: 128, Steps: 58 | Train Loss: 0.0385580  Test Loss: 0.1949749 Test Accuracy: 0.9222939  Test weighted F1: 0.9221029  Test macro F1 0.9232961 \n",
      "Epoch: 129 cost time: 0.9084751605987549\n",
      "TEST: Epoch: 129, Steps: 58 | Train Loss: 0.0405296  Test Loss: 0.1754835 Test Accuracy: 0.9348490  Test weighted F1: 0.9347789  Test macro F1 0.9352598 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130 cost time: 0.9109640121459961\n",
      "TEST: Epoch: 130, Steps: 58 | Train Loss: 0.0398935  Test Loss: 0.1733625 Test Accuracy: 0.9328130  Test weighted F1: 0.9327793  Test macro F1 0.9338943 \n",
      "Epoch: 131 cost time: 0.9088172912597656\n",
      "TEST: Epoch: 131, Steps: 58 | Train Loss: 0.0391861  Test Loss: 0.1748250 Test Accuracy: 0.9324737  Test weighted F1: 0.9323722  Test macro F1 0.9331939 \n",
      "Epoch: 132 cost time: 0.8751966953277588\n",
      "TEST: Epoch: 132, Steps: 58 | Train Loss: 0.0335175  Test Loss: 0.2066827 Test Accuracy: 0.9253478  Test weighted F1: 0.9250014  Test macro F1 0.9258403 \n",
      "Epoch: 133 cost time: 0.8581933975219727\n",
      "TEST: Epoch: 133, Steps: 58 | Train Loss: 0.0363424  Test Loss: 0.1826414 Test Accuracy: 0.9297591  Test weighted F1: 0.9296507  Test macro F1 0.9306049 \n",
      "Epoch: 134 cost time: 0.8741974830627441\n",
      "TEST: Epoch: 134, Steps: 58 | Train Loss: 0.0343956  Test Loss: 0.1877827 Test Accuracy: 0.9345097  Test weighted F1: 0.9343425  Test macro F1 0.9349675 \n",
      "Epoch: 135 cost time: 0.8831980228424072\n",
      "TEST: Epoch: 135, Steps: 58 | Train Loss: 0.0333736  Test Loss: 0.1938197 Test Accuracy: 0.9311164  Test weighted F1: 0.9310010  Test macro F1 0.9317962 \n",
      "Epoch: 136 cost time: 0.8811984062194824\n",
      "TEST: Epoch: 136, Steps: 58 | Train Loss: 0.0337002  Test Loss: 0.1683500 Test Accuracy: 0.9385816  Test weighted F1: 0.9384917  Test macro F1 0.9391323 \n",
      "Epoch: 137 cost time: 0.8771970272064209\n",
      "TEST: Epoch: 137, Steps: 58 | Train Loss: 0.0352639  Test Loss: 0.1739281 Test Accuracy: 0.9362063  Test weighted F1: 0.9361298  Test macro F1 0.9369869 \n",
      "Epoch: 138 cost time: 0.8621945381164551\n",
      "TEST: Epoch: 138, Steps: 58 | Train Loss: 0.0366472  Test Loss: 0.1906402 Test Accuracy: 0.9277231  Test weighted F1: 0.9275762  Test macro F1 0.9284015 \n",
      "Epoch: 139 cost time: 0.8531932830810547\n",
      "TEST: Epoch: 139, Steps: 58 | Train Loss: 0.0335015  Test Loss: 0.1803691 Test Accuracy: 0.9317950  Test weighted F1: 0.9317225  Test macro F1 0.9325458 \n",
      "Epoch: 140 cost time: 0.8581926822662354\n",
      "TEST: Epoch: 140, Steps: 58 | Train Loss: 0.0370753  Test Loss: 0.1906286 Test Accuracy: 0.9273838  Test weighted F1: 0.9274466  Test macro F1 0.9291003 \n",
      "Epoch: 141 cost time: 0.8707301616668701\n",
      "TEST: Epoch: 141, Steps: 58 | Train Loss: 0.0355904  Test Loss: 0.1657839 Test Accuracy: 0.9392603  Test weighted F1: 0.9391721  Test macro F1 0.9399015 \n",
      "Epoch: 142 cost time: 0.8651988506317139\n",
      "TEST: Epoch: 142, Steps: 58 | Train Loss: 0.0332941  Test Loss: 0.1673296 Test Accuracy: 0.9368850  Test weighted F1: 0.9367889  Test macro F1 0.9375721 \n",
      "Epoch: 143 cost time: 0.8531918525695801\n",
      "TEST: Epoch: 143, Steps: 58 | Train Loss: 0.0359902  Test Loss: 0.1639005 Test Accuracy: 0.9433322  Test weighted F1: 0.9432740  Test macro F1 0.9441510 \n",
      "Epoch: 144 cost time: 0.8614678382873535\n",
      "TEST: Epoch: 144, Steps: 58 | Train Loss: 0.0325703  Test Loss: 0.1855353 Test Accuracy: 0.9419749  Test weighted F1: 0.9416511  Test macro F1 0.9419403 \n",
      "Epoch: 145 cost time: 0.8515200614929199\n",
      "TEST: Epoch: 145, Steps: 58 | Train Loss: 0.0359659  Test Loss: 0.1659319 Test Accuracy: 0.9423142  Test weighted F1: 0.9421837  Test macro F1 0.9428052 \n",
      "Epoch: 146 cost time: 0.8571915626525879\n",
      "TEST: Epoch: 146, Steps: 58 | Train Loss: 0.0337208  Test Loss: 0.1837780 Test Accuracy: 0.9294197  Test weighted F1: 0.9292478  Test macro F1 0.9300631 \n",
      "Epoch: 147 cost time: 0.8611938953399658\n",
      "TEST: Epoch: 147, Steps: 58 | Train Loss: 0.0323712  Test Loss: 0.1661832 Test Accuracy: 0.9433322  Test weighted F1: 0.9431929  Test macro F1 0.9436869 \n",
      "Epoch: 148 cost time: 0.8553402423858643\n",
      "TEST: Epoch: 148, Steps: 58 | Train Loss: 0.0315530  Test Loss: 0.1648532 Test Accuracy: 0.9412962  Test weighted F1: 0.9410720  Test macro F1 0.9413232 \n",
      "Epoch: 149 cost time: 0.883033037185669\n",
      "TEST: Epoch: 149, Steps: 58 | Train Loss: 0.0324769  Test Loss: 0.1801304 Test Accuracy: 0.9379030  Test weighted F1: 0.9376843  Test macro F1 0.9382664 \n",
      "Epoch: 150 cost time: 0.892855167388916\n",
      "TEST: Epoch: 150, Steps: 58 | Train Loss: 0.0304693  Test Loss: 0.1612553 Test Accuracy: 0.9440109  Test weighted F1: 0.9438575  Test macro F1 0.9442397 \n",
      "Epoch: 151 cost time: 0.9063799381256104\n",
      "TEST: Epoch: 151, Steps: 58 | Train Loss: 0.0308057  Test Loss: 0.1588268 Test Accuracy: 0.9436715  Test weighted F1: 0.9435068  Test macro F1 0.9439870 \n",
      "Epoch: 152 cost time: 0.9206278324127197\n",
      "TEST: Epoch: 152, Steps: 58 | Train Loss: 0.0339325  Test Loss: 0.1685924 Test Accuracy: 0.9389209  Test weighted F1: 0.9387850  Test macro F1 0.9395200 \n",
      "Epoch: 153 cost time: 0.9150640964508057\n",
      "TEST: Epoch: 153, Steps: 58 | Train Loss: 0.0281607  Test Loss: 0.1698532 Test Accuracy: 0.9412962  Test weighted F1: 0.9410776  Test macro F1 0.9415934 \n",
      "Epoch: 154 cost time: 0.8924095630645752\n",
      "TEST: Epoch: 154, Steps: 58 | Train Loss: 0.0305208  Test Loss: 0.1590768 Test Accuracy: 0.9406176  Test weighted F1: 0.9404290  Test macro F1 0.9412026 \n",
      "Epoch: 155 cost time: 0.8810946941375732\n",
      "TEST: Epoch: 155, Steps: 58 | Train Loss: 0.0300037  Test Loss: 0.1755457 Test Accuracy: 0.9389209  Test weighted F1: 0.9387014  Test macro F1 0.9391246 \n",
      "Epoch: 156 cost time: 0.8907322883605957\n",
      "TEST: Epoch: 156, Steps: 58 | Train Loss: 0.0259125  Test Loss: 0.1681191 Test Accuracy: 0.9412962  Test weighted F1: 0.9411775  Test macro F1 0.9419072 \n",
      "Epoch: 157 cost time: 0.8878648281097412\n",
      "TEST: Epoch: 157, Steps: 58 | Train Loss: 0.0323448  Test Loss: 0.1693548 Test Accuracy: 0.9409569  Test weighted F1: 0.9406588  Test macro F1 0.9410239 \n",
      "Epoch: 158 cost time: 0.881779670715332\n",
      "TEST: Epoch: 158, Steps: 58 | Train Loss: 0.0275637  Test Loss: 0.1776876 Test Accuracy: 0.9402782  Test weighted F1: 0.9400905  Test macro F1 0.9408256 \n",
      "Epoch: 159 cost time: 0.8892354965209961\n",
      "TEST: Epoch: 159, Steps: 58 | Train Loss: 0.0257529  Test Loss: 0.1725804 Test Accuracy: 0.9406176  Test weighted F1: 0.9404088  Test macro F1 0.9406840 \n",
      "Epoch: 160 cost time: 0.8764190673828125\n",
      "TEST: Epoch: 160, Steps: 58 | Train Loss: 0.0278835  Test Loss: 0.1782986 Test Accuracy: 0.9365456  Test weighted F1: 0.9362569  Test macro F1 0.9365665 \n",
      "Epoch: 161 cost time: 0.865236759185791\n",
      "TEST: Epoch: 161, Steps: 58 | Train Loss: 0.0298223  Test Loss: 0.1728123 Test Accuracy: 0.9395996  Test weighted F1: 0.9393725  Test macro F1 0.9397488 \n",
      "Epoch: 162 cost time: 0.8672420978546143\n",
      "TEST: Epoch: 162, Steps: 58 | Train Loss: 0.0284247  Test Loss: 0.1613561 Test Accuracy: 0.9406176  Test weighted F1: 0.9404848  Test macro F1 0.9412069 \n",
      "Epoch: 163 cost time: 0.8922061920166016\n",
      "TEST: Epoch: 163, Steps: 58 | Train Loss: 0.0258166  Test Loss: 0.1584724 Test Accuracy: 0.9443502  Test weighted F1: 0.9441848  Test macro F1 0.9445579 \n",
      "Epoch: 164 cost time: 0.8831980228424072\n",
      "TEST: Epoch: 164, Steps: 58 | Train Loss: 0.0287905  Test Loss: 0.1640915 Test Accuracy: 0.9480828  Test weighted F1: 0.9479466  Test macro F1 0.9485386 \n",
      "Epoch: 165 cost time: 0.8912003040313721\n",
      "TEST: Epoch: 165, Steps: 58 | Train Loss: 0.0264929  Test Loss: 0.2001166 Test Accuracy: 0.9317950  Test weighted F1: 0.9315834  Test macro F1 0.9318742 \n",
      "Epoch: 166 cost time: 0.8932223320007324\n",
      "TEST: Epoch: 166, Steps: 58 | Train Loss: 0.0321577  Test Loss: 0.1889007 Test Accuracy: 0.9260265  Test weighted F1: 0.9260109  Test macro F1 0.9275570 \n",
      "Epoch: 167 cost time: 0.8821976184844971\n",
      "TEST: Epoch: 167, Steps: 58 | Train Loss: 0.0303457  Test Loss: 0.1632096 Test Accuracy: 0.9443502  Test weighted F1: 0.9442130  Test macro F1 0.9448329 \n",
      "Epoch: 168 cost time: 0.900202751159668\n",
      "TEST: Epoch: 168, Steps: 58 | Train Loss: 0.0263306  Test Loss: 0.1752031 Test Accuracy: 0.9399389  Test weighted F1: 0.9397629  Test macro F1 0.9404536 \n",
      "Epoch: 169 cost time: 0.8751976490020752\n",
      "TEST: Epoch: 169, Steps: 58 | Train Loss: 0.0284975  Test Loss: 0.1820887 Test Accuracy: 0.9290804  Test weighted F1: 0.9290010  Test macro F1 0.9301365 \n",
      "Epoch: 170 cost time: 0.8942019939422607\n",
      "TEST: Epoch: 170, Steps: 58 | Train Loss: 0.0248615  Test Loss: 0.1768209 Test Accuracy: 0.9324737  Test weighted F1: 0.9323444  Test macro F1 0.9327945 \n",
      "Epoch: 171 cost time: 0.8611941337585449\n",
      "TEST: Epoch: 171, Steps: 58 | Train Loss: 0.0254226  Test Loss: 0.1635562 Test Accuracy: 0.9419749  Test weighted F1: 0.9418361  Test macro F1 0.9425156 \n",
      "Epoch: 172 cost time: 0.866194486618042\n",
      "TEST: Epoch: 172, Steps: 58 | Train Loss: 0.0268629  Test Loss: 0.1989683 Test Accuracy: 0.9372243  Test weighted F1: 0.9370692  Test macro F1 0.9378655 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 173 cost time: 0.8611936569213867\n",
      "TEST: Epoch: 173, Steps: 58 | Train Loss: 0.0238648  Test Loss: 0.1712728 Test Accuracy: 0.9429929  Test weighted F1: 0.9427710  Test macro F1 0.9430781 \n",
      "Epoch: 174 cost time: 0.8721380233764648\n",
      "TEST: Epoch: 174, Steps: 58 | Train Loss: 0.0237802  Test Loss: 0.1630884 Test Accuracy: 0.9433322  Test weighted F1: 0.9432086  Test macro F1 0.9436194 \n",
      "Epoch: 175 cost time: 0.8541934490203857\n",
      "TEST: Epoch: 175, Steps: 58 | Train Loss: 0.0265081  Test Loss: 0.1797909 Test Accuracy: 0.9416356  Test weighted F1: 0.9414710  Test macro F1 0.9420666 \n",
      "Epoch: 176 cost time: 0.8612117767333984\n",
      "TEST: Epoch: 176, Steps: 58 | Train Loss: 0.0300313  Test Loss: 0.1586357 Test Accuracy: 0.9419749  Test weighted F1: 0.9418982  Test macro F1 0.9426059 \n",
      "Epoch: 177 cost time: 0.8591923713684082\n",
      "TEST: Epoch: 177, Steps: 58 | Train Loss: 0.0224911  Test Loss: 0.1790916 Test Accuracy: 0.9402782  Test weighted F1: 0.9400618  Test macro F1 0.9403761 \n",
      "Epoch: 178 cost time: 0.8481912612915039\n",
      "TEST: Epoch: 178, Steps: 58 | Train Loss: 0.0226925  Test Loss: 0.1850067 Test Accuracy: 0.9460468  Test weighted F1: 0.9457388  Test macro F1 0.9463356 \n",
      "Epoch: 179 cost time: 0.8596985340118408\n",
      "TEST: Epoch: 179, Steps: 58 | Train Loss: 0.0277515  Test Loss: 0.1711205 Test Accuracy: 0.9440109  Test weighted F1: 0.9438183  Test macro F1 0.9444909 \n",
      "Epoch: 180 cost time: 0.8521921634674072\n",
      "TEST: Epoch: 180, Steps: 58 | Train Loss: 0.0248861  Test Loss: 0.1682507 Test Accuracy: 0.9480828  Test weighted F1: 0.9478887  Test macro F1 0.9482839 \n",
      "Epoch: 181 cost time: 0.8551936149597168\n",
      "TEST: Epoch: 181, Steps: 58 | Train Loss: 0.0282318  Test Loss: 0.2046607 Test Accuracy: 0.9365456  Test weighted F1: 0.9362951  Test macro F1 0.9367614 \n",
      "Epoch: 182 cost time: 0.854809045791626\n",
      "TEST: Epoch: 182, Steps: 58 | Train Loss: 0.0220770  Test Loss: 0.1857283 Test Accuracy: 0.9368850  Test weighted F1: 0.9367103  Test macro F1 0.9368918 \n",
      "Epoch: 183 cost time: 0.8637101650238037\n",
      "TEST: Epoch: 183, Steps: 58 | Train Loss: 0.0238136  Test Loss: 0.2052527 Test Accuracy: 0.9294197  Test weighted F1: 0.9292260  Test macro F1 0.9297715 \n",
      "Epoch: 184 cost time: 0.8852005004882812\n",
      "TEST: Epoch: 184, Steps: 58 | Train Loss: 0.0230184  Test Loss: 0.1675938 Test Accuracy: 0.9463862  Test weighted F1: 0.9462544  Test macro F1 0.9470152 \n",
      "Epoch: 185 cost time: 0.8581936359405518\n",
      "TEST: Epoch: 185, Steps: 58 | Train Loss: 0.0249409  Test Loss: 0.1803177 Test Accuracy: 0.9402782  Test weighted F1: 0.9400789  Test macro F1 0.9405550 \n",
      "Epoch: 186 cost time: 0.8511919975280762\n",
      "TEST: Epoch: 186, Steps: 58 | Train Loss: 0.0225468  Test Loss: 0.1717598 Test Accuracy: 0.9443502  Test weighted F1: 0.9440239  Test macro F1 0.9443006 \n",
      "Epoch: 187 cost time: 0.848752498626709\n",
      "TEST: Epoch: 187, Steps: 58 | Train Loss: 0.0218413  Test Loss: 0.1801709 Test Accuracy: 0.9379030  Test weighted F1: 0.9377637  Test macro F1 0.9383200 \n",
      "Epoch: 188 cost time: 0.8509886264801025\n",
      "TEST: Epoch: 188, Steps: 58 | Train Loss: 0.0257956  Test Loss: 0.1665489 Test Accuracy: 0.9460468  Test weighted F1: 0.9459302  Test macro F1 0.9465894 \n",
      "Epoch: 189 cost time: 0.8603513240814209\n",
      "TEST: Epoch: 189, Steps: 58 | Train Loss: 0.0230245  Test Loss: 0.1782783 Test Accuracy: 0.9426535  Test weighted F1: 0.9424763  Test macro F1 0.9430021 \n",
      "Epoch: 190 cost time: 0.8541927337646484\n",
      "TEST: Epoch: 190, Steps: 58 | Train Loss: 0.0237991  Test Loss: 0.1919175 Test Accuracy: 0.9399389  Test weighted F1: 0.9396992  Test macro F1 0.9398096 \n",
      "Epoch: 191 cost time: 0.8661954402923584\n",
      "TEST: Epoch: 191, Steps: 58 | Train Loss: 0.0213016  Test Loss: 0.1855317 Test Accuracy: 0.9416356  Test weighted F1: 0.9414177  Test macro F1 0.9421269 \n",
      "Epoch: 192 cost time: 0.850191593170166\n",
      "TEST: Epoch: 192, Steps: 58 | Train Loss: 0.0201636  Test Loss: 0.1744937 Test Accuracy: 0.9446895  Test weighted F1: 0.9444413  Test macro F1 0.9448638 \n",
      "Epoch: 193 cost time: 0.852191686630249\n",
      "TEST: Epoch: 193, Steps: 58 | Train Loss: 0.0211570  Test Loss: 0.1668874 Test Accuracy: 0.9467255  Test weighted F1: 0.9464975  Test macro F1 0.9469958 \n",
      "Epoch: 194 cost time: 0.8512086868286133\n",
      "TEST: Epoch: 194, Steps: 58 | Train Loss: 0.0196868  Test Loss: 0.1848296 Test Accuracy: 0.9412962  Test weighted F1: 0.9410196  Test macro F1 0.9414257 \n",
      "Epoch: 195 cost time: 0.8611941337585449\n",
      "TEST: Epoch: 195, Steps: 58 | Train Loss: 0.0251506  Test Loss: 0.1822789 Test Accuracy: 0.9395996  Test weighted F1: 0.9393560  Test macro F1 0.9397186 \n",
      "Epoch: 196 cost time: 0.8501920700073242\n",
      "TEST: Epoch: 196, Steps: 58 | Train Loss: 0.0226824  Test Loss: 0.1800128 Test Accuracy: 0.9484221  Test weighted F1: 0.9480990  Test macro F1 0.9482023 \n",
      "Epoch: 197 cost time: 0.8491907119750977\n",
      "TEST: Epoch: 197, Steps: 58 | Train Loss: 0.0221445  Test Loss: 0.1571146 Test Accuracy: 0.9446895  Test weighted F1: 0.9445415  Test macro F1 0.9447122 \n",
      "Epoch: 198 cost time: 0.8521914482116699\n",
      "TEST: Epoch: 198, Steps: 58 | Train Loss: 0.0223846  Test Loss: 0.1890465 Test Accuracy: 0.9423142  Test weighted F1: 0.9420098  Test macro F1 0.9421397 \n",
      "Epoch: 199 cost time: 0.8531918525695801\n",
      "TEST: Epoch: 199, Steps: 58 | Train Loss: 0.0253945  Test Loss: 0.1645708 Test Accuracy: 0.9419749  Test weighted F1: 0.9418707  Test macro F1 0.9427949 \n",
      "Epoch: 200 cost time: 0.8571922779083252\n",
      "TEST: Epoch: 200, Steps: 58 | Train Loss: 0.0229071  Test Loss: 0.1683999 Test Accuracy: 0.9409569  Test weighted F1: 0.9407805  Test macro F1 0.9413415 \n",
      "Epoch: 201 cost time: 0.864501953125\n",
      "TEST: Epoch: 201, Steps: 58 | Train Loss: 0.0258095  Test Loss: 0.1663097 Test Accuracy: 0.9484221  Test weighted F1: 0.9482126  Test macro F1 0.9485057 \n",
      "Epoch: 202 cost time: 0.8581936359405518\n",
      "TEST: Epoch: 202, Steps: 58 | Train Loss: 0.0191416  Test Loss: 0.1774053 Test Accuracy: 0.9385816  Test weighted F1: 0.9383687  Test macro F1 0.9387878 \n",
      "Epoch: 203 cost time: 0.8511917591094971\n",
      "TEST: Epoch: 203, Steps: 58 | Train Loss: 0.0223030  Test Loss: 0.1990505 Test Accuracy: 0.9389209  Test weighted F1: 0.9386779  Test macro F1 0.9390418 \n",
      "Epoch: 204 cost time: 0.8515315055847168\n",
      "TEST: Epoch: 204, Steps: 58 | Train Loss: 0.0212649  Test Loss: 0.1794376 Test Accuracy: 0.9460468  Test weighted F1: 0.9458322  Test macro F1 0.9463132 \n",
      "Epoch: 205 cost time: 0.8715770244598389\n",
      "TEST: Epoch: 205, Steps: 58 | Train Loss: 0.0176174  Test Loss: 0.1795555 Test Accuracy: 0.9419749  Test weighted F1: 0.9418164  Test macro F1 0.9423020 \n",
      "Epoch: 206 cost time: 0.8681957721710205\n",
      "TEST: Epoch: 206, Steps: 58 | Train Loss: 0.0209025  Test Loss: 0.1821106 Test Accuracy: 0.9480828  Test weighted F1: 0.9478413  Test macro F1 0.9481157 \n",
      "Epoch: 207 cost time: 0.8521921634674072\n",
      "TEST: Epoch: 207, Steps: 58 | Train Loss: 0.0211591  Test Loss: 0.1722347 Test Accuracy: 0.9419749  Test weighted F1: 0.9418701  Test macro F1 0.9423834 \n",
      "Epoch: 208 cost time: 0.8641958236694336\n",
      "TEST: Epoch: 208, Steps: 58 | Train Loss: 0.0209425  Test Loss: 0.1621006 Test Accuracy: 0.9477435  Test weighted F1: 0.9475659  Test macro F1 0.9480332 \n",
      "Epoch: 209 cost time: 0.8621306419372559\n",
      "TEST: Epoch: 209, Steps: 58 | Train Loss: 0.0235655  Test Loss: 0.1771163 Test Accuracy: 0.9440109  Test weighted F1: 0.9438771  Test macro F1 0.9443228 \n",
      "Epoch: 210 cost time: 0.8501918315887451\n",
      "TEST: Epoch: 210, Steps: 58 | Train Loss: 0.0229466  Test Loss: 0.1914885 Test Accuracy: 0.9453682  Test weighted F1: 0.9450875  Test macro F1 0.9451601 \n",
      "Epoch: 211 cost time: 0.8721964359283447\n",
      "TEST: Epoch: 211, Steps: 58 | Train Loss: 0.0215814  Test Loss: 0.1797106 Test Accuracy: 0.9446895  Test weighted F1: 0.9444330  Test macro F1 0.9448117 \n",
      "Epoch: 212 cost time: 0.8611946105957031\n",
      "TEST: Epoch: 212, Steps: 58 | Train Loss: 0.0187512  Test Loss: 0.2010937 Test Accuracy: 0.9372243  Test weighted F1: 0.9370277  Test macro F1 0.9375257 \n",
      "Epoch: 213 cost time: 0.8601934909820557\n",
      "TEST: Epoch: 213, Steps: 58 | Train Loss: 0.0192479  Test Loss: 0.1710955 Test Accuracy: 0.9426535  Test weighted F1: 0.9424417  Test macro F1 0.9429078 \n",
      "Epoch: 214 cost time: 0.8551928997039795\n",
      "TEST: Epoch: 214, Steps: 58 | Train Loss: 0.0205522  Test Loss: 0.1689327 Test Accuracy: 0.9474041  Test weighted F1: 0.9472310  Test macro F1 0.9478682 \n",
      "Epoch: 215 cost time: 0.8651950359344482\n",
      "TEST: Epoch: 215, Steps: 58 | Train Loss: 0.0187529  Test Loss: 0.1563654 Test Accuracy: 0.9487615  Test weighted F1: 0.9486314  Test macro F1 0.9492139 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 216 cost time: 0.8852005004882812\n",
      "TEST: Epoch: 216, Steps: 58 | Train Loss: 0.0211344  Test Loss: 0.1623991 Test Accuracy: 0.9467255  Test weighted F1: 0.9467130  Test macro F1 0.9475197 \n",
      "Epoch: 217 cost time: 0.8671951293945312\n",
      "TEST: Epoch: 217, Steps: 58 | Train Loss: 0.0188515  Test Loss: 0.1847085 Test Accuracy: 0.9416356  Test weighted F1: 0.9414446  Test macro F1 0.9417596 \n",
      "Epoch: 218 cost time: 0.8581926822662354\n",
      "TEST: Epoch: 218, Steps: 58 | Train Loss: 0.0226432  Test Loss: 0.1791437 Test Accuracy: 0.9440109  Test weighted F1: 0.9439572  Test macro F1 0.9448576 \n",
      "Epoch: 219 cost time: 0.8561930656433105\n",
      "TEST: Epoch: 219, Steps: 58 | Train Loss: 0.0212983  Test Loss: 0.1835594 Test Accuracy: 0.9463862  Test weighted F1: 0.9462941  Test macro F1 0.9469694 \n",
      "Epoch: 220 cost time: 0.8501937389373779\n",
      "TEST: Epoch: 220, Steps: 58 | Train Loss: 0.0218292  Test Loss: 0.1985550 Test Accuracy: 0.9433322  Test weighted F1: 0.9430840  Test macro F1 0.9438402 \n",
      "Epoch: 221 cost time: 0.8581936359405518\n",
      "TEST: Epoch: 221, Steps: 58 | Train Loss: 0.0189539  Test Loss: 0.1843640 Test Accuracy: 0.9419749  Test weighted F1: 0.9416854  Test macro F1 0.9418630 \n",
      "Epoch: 222 cost time: 0.8561921119689941\n",
      "TEST: Epoch: 222, Steps: 58 | Train Loss: 0.0170181  Test Loss: 0.1773464 Test Accuracy: 0.9423142  Test weighted F1: 0.9421040  Test macro F1 0.9425883 \n",
      "Epoch: 223 cost time: 0.8531918525695801\n",
      "TEST: Epoch: 223, Steps: 58 | Train Loss: 0.0159582  Test Loss: 0.1565726 Test Accuracy: 0.9484221  Test weighted F1: 0.9482288  Test macro F1 0.9486352 \n",
      "Epoch: 224 cost time: 0.8571939468383789\n",
      "TEST: Epoch: 224, Steps: 58 | Train Loss: 0.0207630  Test Loss: 0.1808216 Test Accuracy: 0.9463862  Test weighted F1: 0.9461791  Test macro F1 0.9468464 \n",
      "Epoch: 225 cost time: 0.8751976490020752\n",
      "TEST: Epoch: 225, Steps: 58 | Train Loss: 0.0177105  Test Loss: 0.1606512 Test Accuracy: 0.9501188  Test weighted F1: 0.9499282  Test macro F1 0.9502838 \n",
      "Epoch: 226 cost time: 0.8671951293945312\n",
      "TEST: Epoch: 226, Steps: 58 | Train Loss: 0.0173024  Test Loss: 0.1707195 Test Accuracy: 0.9477435  Test weighted F1: 0.9475817  Test macro F1 0.9482456 \n",
      "Epoch: 227 cost time: 0.8621935844421387\n",
      "TEST: Epoch: 227, Steps: 58 | Train Loss: 0.0171396  Test Loss: 0.1948251 Test Accuracy: 0.9423142  Test weighted F1: 0.9419852  Test macro F1 0.9426267 \n",
      "Epoch: 228 cost time: 0.8561923503875732\n",
      "TEST: Epoch: 228, Steps: 58 | Train Loss: 0.0181702  Test Loss: 0.1680361 Test Accuracy: 0.9480828  Test weighted F1: 0.9479379  Test macro F1 0.9483488 \n",
      "Epoch: 229 cost time: 0.840723991394043\n",
      "TEST: Epoch: 229, Steps: 58 | Train Loss: 0.0175466  Test Loss: 0.1983043 Test Accuracy: 0.9412962  Test weighted F1: 0.9408968  Test macro F1 0.9411771 \n",
      "Epoch: 230 cost time: 0.8453705310821533\n",
      "TEST: Epoch: 230, Steps: 58 | Train Loss: 0.0191295  Test Loss: 0.2018346 Test Accuracy: 0.9355277  Test weighted F1: 0.9353960  Test macro F1 0.9357561 \n",
      "Epoch: 231 cost time: 0.8490638732910156\n",
      "TEST: Epoch: 231, Steps: 58 | Train Loss: 0.0161531  Test Loss: 0.1961128 Test Accuracy: 0.9412962  Test weighted F1: 0.9410163  Test macro F1 0.9416809 \n",
      "Epoch: 232 cost time: 0.8481895923614502\n",
      "TEST: Epoch: 232, Steps: 58 | Train Loss: 0.0180650  Test Loss: 0.1650950 Test Accuracy: 0.9433322  Test weighted F1: 0.9432349  Test macro F1 0.9439756 \n",
      "Epoch: 233 cost time: 0.8401894569396973\n",
      "TEST: Epoch: 233, Steps: 58 | Train Loss: 0.0169799  Test Loss: 0.1854589 Test Accuracy: 0.9450288  Test weighted F1: 0.9447431  Test macro F1 0.9450454 \n",
      "Epoch: 234 cost time: 0.8621940612792969\n",
      "TEST: Epoch: 234, Steps: 58 | Train Loss: 0.0154463  Test Loss: 0.1753774 Test Accuracy: 0.9443502  Test weighted F1: 0.9442382  Test macro F1 0.9448051 \n",
      "Epoch: 235 cost time: 0.8562870025634766\n",
      "TEST: Epoch: 235, Steps: 58 | Train Loss: 0.0172161  Test Loss: 0.1699198 Test Accuracy: 0.9480828  Test weighted F1: 0.9479005  Test macro F1 0.9483525 \n",
      "Epoch: 236 cost time: 0.862595796585083\n",
      "TEST: Epoch: 236, Steps: 58 | Train Loss: 0.0174645  Test Loss: 0.1590670 Test Accuracy: 0.9470648  Test weighted F1: 0.9469929  Test macro F1 0.9476591 \n",
      "Epoch: 237 cost time: 0.8481912612915039\n",
      "TEST: Epoch: 237, Steps: 58 | Train Loss: 0.0197191  Test Loss: 0.1969147 Test Accuracy: 0.9341703  Test weighted F1: 0.9339440  Test macro F1 0.9340689 \n",
      "Epoch: 238 cost time: 0.8541929721832275\n",
      "TEST: Epoch: 238, Steps: 58 | Train Loss: 0.0177412  Test Loss: 0.1950476 Test Accuracy: 0.9480828  Test weighted F1: 0.9478994  Test macro F1 0.9484078 \n",
      "Epoch: 239 cost time: 0.8751969337463379\n",
      "TEST: Epoch: 239, Steps: 58 | Train Loss: 0.0190616  Test Loss: 0.1878717 Test Accuracy: 0.9446895  Test weighted F1: 0.9444011  Test macro F1 0.9448849 \n",
      "Epoch: 240 cost time: 0.9027206897735596\n",
      "TEST: Epoch: 240, Steps: 58 | Train Loss: 0.0200460  Test Loss: 0.1672810 Test Accuracy: 0.9497794  Test weighted F1: 0.9495983  Test macro F1 0.9501837 \n",
      "Epoch: 241 cost time: 0.9171772003173828\n",
      "TEST: Epoch: 241, Steps: 58 | Train Loss: 0.0181151  Test Loss: 0.1920971 Test Accuracy: 0.9467255  Test weighted F1: 0.9464016  Test macro F1 0.9467944 \n",
      "Epoch: 242 cost time: 0.900324821472168\n",
      "TEST: Epoch: 242, Steps: 58 | Train Loss: 0.0151715  Test Loss: 0.1763270 Test Accuracy: 0.9484221  Test weighted F1: 0.9482201  Test macro F1 0.9485568 \n",
      "Epoch: 243 cost time: 0.935816764831543\n",
      "TEST: Epoch: 243, Steps: 58 | Train Loss: 0.0186642  Test Loss: 0.1787148 Test Accuracy: 0.9497794  Test weighted F1: 0.9494988  Test macro F1 0.9498231 \n",
      "Epoch: 244 cost time: 0.9107475280761719\n",
      "TEST: Epoch: 244, Steps: 58 | Train Loss: 0.0159976  Test Loss: 0.1900973 Test Accuracy: 0.9480828  Test weighted F1: 0.9477628  Test macro F1 0.9480674 \n",
      "Epoch: 245 cost time: 0.9046032428741455\n",
      "TEST: Epoch: 245, Steps: 58 | Train Loss: 0.0163190  Test Loss: 0.1613782 Test Accuracy: 0.9507974  Test weighted F1: 0.9506992  Test macro F1 0.9511038 \n",
      "Epoch: 246 cost time: 0.9189283847808838\n",
      "TEST: Epoch: 246, Steps: 58 | Train Loss: 0.0179843  Test Loss: 0.1916073 Test Accuracy: 0.9457075  Test weighted F1: 0.9455493  Test macro F1 0.9461489 \n",
      "Epoch: 247 cost time: 0.9064428806304932\n",
      "TEST: Epoch: 247, Steps: 58 | Train Loss: 0.0157117  Test Loss: 0.1766309 Test Accuracy: 0.9477435  Test weighted F1: 0.9476261  Test macro F1 0.9482434 \n",
      "Epoch: 248 cost time: 0.9110159873962402\n",
      "TEST: Epoch: 248, Steps: 58 | Train Loss: 0.0186626  Test Loss: 0.1955163 Test Accuracy: 0.9399389  Test weighted F1: 0.9398404  Test macro F1 0.9403205 \n",
      "Epoch: 249 cost time: 0.9068655967712402\n",
      "TEST: Epoch: 249, Steps: 58 | Train Loss: 0.0168355  Test Loss: 0.1878932 Test Accuracy: 0.9446895  Test weighted F1: 0.9445482  Test macro F1 0.9448001 \n",
      "Epoch: 250 cost time: 0.9093813896179199\n",
      "TEST: Epoch: 250, Steps: 58 | Train Loss: 0.0182920  Test Loss: 0.1658078 Test Accuracy: 0.9497794  Test weighted F1: 0.9495925  Test macro F1 0.9499953 \n",
      "Epoch: 251 cost time: 0.9146411418914795\n",
      "TEST: Epoch: 251, Steps: 58 | Train Loss: 0.0172067  Test Loss: 0.1882919 Test Accuracy: 0.9453682  Test weighted F1: 0.9452190  Test macro F1 0.9456677 \n",
      "Epoch: 252 cost time: 0.9039044380187988\n",
      "TEST: Epoch: 252, Steps: 58 | Train Loss: 0.0160802  Test Loss: 0.1665419 Test Accuracy: 0.9484221  Test weighted F1: 0.9483560  Test macro F1 0.9488539 \n",
      "Epoch: 253 cost time: 0.9166545867919922\n",
      "TEST: Epoch: 253, Steps: 58 | Train Loss: 0.0173626  Test Loss: 0.1766477 Test Accuracy: 0.9460468  Test weighted F1: 0.9458857  Test macro F1 0.9463765 \n",
      "Epoch: 254 cost time: 0.8977553844451904\n",
      "TEST: Epoch: 254, Steps: 58 | Train Loss: 0.0151593  Test Loss: 0.1857592 Test Accuracy: 0.9436715  Test weighted F1: 0.9433415  Test macro F1 0.9433310 \n",
      "Epoch: 255 cost time: 0.8978040218353271\n",
      "TEST: Epoch: 255, Steps: 58 | Train Loss: 0.0160447  Test Loss: 0.1809543 Test Accuracy: 0.9467255  Test weighted F1: 0.9465903  Test macro F1 0.9472308 \n",
      "Epoch: 256 cost time: 0.9080064296722412\n",
      "TEST: Epoch: 256, Steps: 58 | Train Loss: 0.0168804  Test Loss: 0.1741158 Test Accuracy: 0.9463862  Test weighted F1: 0.9461856  Test macro F1 0.9465497 \n",
      "Epoch: 257 cost time: 0.9210903644561768\n",
      "TEST: Epoch: 257, Steps: 58 | Train Loss: 0.0154329  Test Loss: 0.2366316 Test Accuracy: 0.9453682  Test weighted F1: 0.9448563  Test macro F1 0.9449775 \n",
      "Epoch: 258 cost time: 0.923973560333252\n",
      "TEST: Epoch: 258, Steps: 58 | Train Loss: 0.0177598  Test Loss: 0.1865091 Test Accuracy: 0.9406176  Test weighted F1: 0.9403965  Test macro F1 0.9406805 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 259 cost time: 0.9239118099212646\n",
      "TEST: Epoch: 259, Steps: 58 | Train Loss: 0.0151378  Test Loss: 0.1815515 Test Accuracy: 0.9457075  Test weighted F1: 0.9455996  Test macro F1 0.9461647 \n",
      "Epoch: 260 cost time: 0.9149584770202637\n",
      "TEST: Epoch: 260, Steps: 58 | Train Loss: 0.0168169  Test Loss: 0.1823458 Test Accuracy: 0.9477435  Test weighted F1: 0.9474752  Test macro F1 0.9477754 \n",
      "Epoch: 261 cost time: 0.9062690734863281\n",
      "TEST: Epoch: 261, Steps: 58 | Train Loss: 0.0204292  Test Loss: 0.1853297 Test Accuracy: 0.9463862  Test weighted F1: 0.9461958  Test macro F1 0.9466660 \n",
      "Epoch: 262 cost time: 0.9143002033233643\n",
      "TEST: Epoch: 262, Steps: 58 | Train Loss: 0.0154190  Test Loss: 0.1925978 Test Accuracy: 0.9474041  Test weighted F1: 0.9471082  Test macro F1 0.9474496 \n",
      "Epoch: 263 cost time: 0.9136111736297607\n",
      "TEST: Epoch: 263, Steps: 58 | Train Loss: 0.0147743  Test Loss: 0.1923957 Test Accuracy: 0.9419749  Test weighted F1: 0.9417270  Test macro F1 0.9418810 \n",
      "Epoch: 264 cost time: 0.9080233573913574\n",
      "TEST: Epoch: 264, Steps: 58 | Train Loss: 0.0191307  Test Loss: 0.1872617 Test Accuracy: 0.9470648  Test weighted F1: 0.9467542  Test macro F1 0.9470050 \n",
      "Epoch: 265 cost time: 0.9119217395782471\n",
      "TEST: Epoch: 265, Steps: 58 | Train Loss: 0.0172793  Test Loss: 0.1902519 Test Accuracy: 0.9436715  Test weighted F1: 0.9434660  Test macro F1 0.9437719 \n",
      "Epoch: 266 cost time: 0.9077215194702148\n",
      "TEST: Epoch: 266, Steps: 58 | Train Loss: 0.0178753  Test Loss: 0.1902040 Test Accuracy: 0.9443502  Test weighted F1: 0.9442205  Test macro F1 0.9445447 \n",
      "Epoch: 267 cost time: 0.912606954574585\n",
      "TEST: Epoch: 267, Steps: 58 | Train Loss: 0.0151107  Test Loss: 0.2003264 Test Accuracy: 0.9389209  Test weighted F1: 0.9386890  Test macro F1 0.9386905 \n",
      "Epoch: 268 cost time: 0.9551701545715332\n",
      "TEST: Epoch: 268, Steps: 58 | Train Loss: 0.0151547  Test Loss: 0.1983407 Test Accuracy: 0.9477435  Test weighted F1: 0.9474929  Test macro F1 0.9478635 \n",
      "Epoch: 269 cost time: 0.9116988182067871\n",
      "TEST: Epoch: 269, Steps: 58 | Train Loss: 0.0125450  Test Loss: 0.1896795 Test Accuracy: 0.9446895  Test weighted F1: 0.9444622  Test macro F1 0.9446272 \n",
      "Epoch: 270 cost time: 0.917914628982544\n",
      "TEST: Epoch: 270, Steps: 58 | Train Loss: 0.0173386  Test Loss: 0.1712588 Test Accuracy: 0.9501188  Test weighted F1: 0.9499106  Test macro F1 0.9504229 \n",
      "Epoch: 271 cost time: 0.8661947250366211\n",
      "TEST: Epoch: 271, Steps: 58 | Train Loss: 0.0152616  Test Loss: 0.1834876 Test Accuracy: 0.9453682  Test weighted F1: 0.9451750  Test macro F1 0.9456087 \n",
      "Epoch: 272 cost time: 0.8708446025848389\n",
      "TEST: Epoch: 272, Steps: 58 | Train Loss: 0.0161007  Test Loss: 0.1956542 Test Accuracy: 0.9392603  Test weighted F1: 0.9392130  Test macro F1 0.9398688 \n",
      "Epoch: 273 cost time: 0.8831102848052979\n",
      "TEST: Epoch: 273, Steps: 58 | Train Loss: 0.0146123  Test Loss: 0.2007957 Test Accuracy: 0.9453682  Test weighted F1: 0.9450873  Test macro F1 0.9454789 \n",
      "Epoch: 274 cost time: 0.8694360256195068\n",
      "TEST: Epoch: 274, Steps: 58 | Train Loss: 0.0154999  Test Loss: 0.2204644 Test Accuracy: 0.9375636  Test weighted F1: 0.9371907  Test macro F1 0.9374160 \n",
      "Epoch: 275 cost time: 0.8581922054290771\n",
      "TEST: Epoch: 275, Steps: 58 | Train Loss: 0.0152908  Test Loss: 0.1841067 Test Accuracy: 0.9460468  Test weighted F1: 0.9457652  Test macro F1 0.9459109 \n",
      "Epoch: 276 cost time: 0.8641953468322754\n",
      "TEST: Epoch: 276, Steps: 58 | Train Loss: 0.0126977  Test Loss: 0.1774536 Test Accuracy: 0.9507974  Test weighted F1: 0.9505856  Test macro F1 0.9509996 \n",
      "Epoch: 277 cost time: 0.879202127456665\n",
      "TEST: Epoch: 277, Steps: 58 | Train Loss: 0.0148645  Test Loss: 0.1794158 Test Accuracy: 0.9477435  Test weighted F1: 0.9474841  Test macro F1 0.9476947 \n",
      "Epoch: 278 cost time: 0.890256404876709\n",
      "TEST: Epoch: 278, Steps: 58 | Train Loss: 0.0143122  Test Loss: 0.1817478 Test Accuracy: 0.9494401  Test weighted F1: 0.9492066  Test macro F1 0.9495609 \n",
      "Epoch: 279 cost time: 0.8931260108947754\n",
      "TEST: Epoch: 279, Steps: 58 | Train Loss: 0.0143269  Test Loss: 0.2015476 Test Accuracy: 0.9399389  Test weighted F1: 0.9396676  Test macro F1 0.9395030 \n",
      "Epoch: 280 cost time: 0.8677616119384766\n",
      "TEST: Epoch: 280, Steps: 58 | Train Loss: 0.0166666  Test Loss: 0.1594220 Test Accuracy: 0.9507974  Test weighted F1: 0.9506439  Test macro F1 0.9511872 \n",
      "Epoch: 281 cost time: 0.8651957511901855\n",
      "TEST: Epoch: 281, Steps: 58 | Train Loss: 0.0162038  Test Loss: 0.2082638 Test Accuracy: 0.9436715  Test weighted F1: 0.9433915  Test macro F1 0.9435537 \n",
      "Epoch: 282 cost time: 0.8673305511474609\n",
      "TEST: Epoch: 282, Steps: 58 | Train Loss: 0.0115870  Test Loss: 0.1725709 Test Accuracy: 0.9504581  Test weighted F1: 0.9502476  Test macro F1 0.9506847 \n",
      "Epoch: 283 cost time: 0.8833229541778564\n",
      "TEST: Epoch: 283, Steps: 58 | Train Loss: 0.0125188  Test Loss: 0.2157595 Test Accuracy: 0.9460468  Test weighted F1: 0.9456421  Test macro F1 0.9454942 \n",
      "Epoch: 284 cost time: 0.8929524421691895\n",
      "TEST: Epoch: 284, Steps: 58 | Train Loss: 0.0143223  Test Loss: 0.1850737 Test Accuracy: 0.9406176  Test weighted F1: 0.9405434  Test macro F1 0.9412658 \n",
      "Epoch: 285 cost time: 0.922764778137207\n",
      "TEST: Epoch: 285, Steps: 58 | Train Loss: 0.0165688  Test Loss: 0.1739391 Test Accuracy: 0.9463862  Test weighted F1: 0.9462554  Test macro F1 0.9468342 \n",
      "Epoch: 286 cost time: 0.9234099388122559\n",
      "TEST: Epoch: 286, Steps: 58 | Train Loss: 0.0160829  Test Loss: 0.1572890 Test Accuracy: 0.9507974  Test weighted F1: 0.9507199  Test macro F1 0.9512382 \n",
      "Epoch: 287 cost time: 0.8984389305114746\n",
      "TEST: Epoch: 287, Steps: 58 | Train Loss: 0.0136406  Test Loss: 0.2172987 Test Accuracy: 0.9426535  Test weighted F1: 0.9422427  Test macro F1 0.9425534 \n",
      "Epoch: 288 cost time: 0.8823692798614502\n",
      "TEST: Epoch: 288, Steps: 58 | Train Loss: 0.0155090  Test Loss: 0.1908262 Test Accuracy: 0.9433322  Test weighted F1: 0.9431251  Test macro F1 0.9432720 \n",
      "Epoch: 289 cost time: 0.9232478141784668\n",
      "TEST: Epoch: 289, Steps: 58 | Train Loss: 0.0156832  Test Loss: 0.1772281 Test Accuracy: 0.9470648  Test weighted F1: 0.9469374  Test macro F1 0.9473810 \n",
      "Epoch: 290 cost time: 0.8897030353546143\n",
      "TEST: Epoch: 290, Steps: 58 | Train Loss: 0.0123243  Test Loss: 0.1767546 Test Accuracy: 0.9491008  Test weighted F1: 0.9489380  Test macro F1 0.9494816 \n",
      "Epoch: 291 cost time: 0.8772943019866943\n",
      "TEST: Epoch: 291, Steps: 58 | Train Loss: 0.0142981  Test Loss: 0.1978101 Test Accuracy: 0.9491008  Test weighted F1: 0.9487497  Test macro F1 0.9490334 \n",
      "Epoch: 292 cost time: 0.8852939605712891\n",
      "TEST: Epoch: 292, Steps: 58 | Train Loss: 0.0156977  Test Loss: 0.1733876 Test Accuracy: 0.9463862  Test weighted F1: 0.9462890  Test macro F1 0.9466462 \n",
      "Epoch: 293 cost time: 0.9114949703216553\n",
      "TEST: Epoch: 293, Steps: 58 | Train Loss: 0.0153340  Test Loss: 0.2009863 Test Accuracy: 0.9494401  Test weighted F1: 0.9491114  Test macro F1 0.9495673 \n",
      "Epoch: 294 cost time: 0.9140222072601318\n",
      "TEST: Epoch: 294, Steps: 58 | Train Loss: 0.0135891  Test Loss: 0.1916175 Test Accuracy: 0.9480828  Test weighted F1: 0.9480059  Test macro F1 0.9486151 \n",
      "Epoch: 295 cost time: 0.9128122329711914\n",
      "TEST: Epoch: 295, Steps: 58 | Train Loss: 0.0127215  Test Loss: 0.2050233 Test Accuracy: 0.9436715  Test weighted F1: 0.9433575  Test macro F1 0.9434120 \n",
      "Epoch: 296 cost time: 0.9213736057281494\n",
      "TEST: Epoch: 296, Steps: 58 | Train Loss: 0.0128590  Test Loss: 0.1881937 Test Accuracy: 0.9474041  Test weighted F1: 0.9471689  Test macro F1 0.9472887 \n",
      "Epoch: 297 cost time: 0.9208905696868896\n",
      "TEST: Epoch: 297, Steps: 58 | Train Loss: 0.0132947  Test Loss: 0.1762382 Test Accuracy: 0.9491008  Test weighted F1: 0.9489593  Test macro F1 0.9491732 \n",
      "Epoch: 298 cost time: 0.9117701053619385\n",
      "TEST: Epoch: 298, Steps: 58 | Train Loss: 0.0117598  Test Loss: 0.2045584 Test Accuracy: 0.9484221  Test weighted F1: 0.9480807  Test macro F1 0.9484981 \n",
      "Epoch: 299 cost time: 0.908719539642334\n",
      "TEST: Epoch: 299, Steps: 58 | Train Loss: 0.0122256  Test Loss: 0.1813681 Test Accuracy: 0.9480828  Test weighted F1: 0.9479842  Test macro F1 0.9484589 \n",
      "Epoch: 300 cost time: 0.900202751159668\n",
      "TEST: Epoch: 300, Steps: 58 | Train Loss: 0.0106293  Test Loss: 0.2231466 Test Accuracy: 0.9470648  Test weighted F1: 0.9466436  Test macro F1 0.9470552 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(train_epochs):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    epoch_time = time.time()\n",
    "\n",
    "    for i, (batch_x,batch_y) in enumerate(train_data_loader):\n",
    "        #start = time.time()\n",
    "\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "\n",
    "        batch_x = batch_x.double().to(device)\n",
    "        batch_y = batch_y.long().to(device)\n",
    "\n",
    "        outputs = model(batch_x)\n",
    "        #print(time.time()-start)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "        #print(time.time()-start)\n",
    "        #print(\"-------------\")\n",
    "\n",
    "    print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n",
    "\n",
    "    train_loss = np.average(train_loss)\n",
    "\n",
    "\n",
    "    test_loss , test_acc, test_f_w,  test_f_macro,  test_f_micro = validation(test_data_loader, criterion)\n",
    "\n",
    "    print(\"TEST: Epoch: {0}, Steps: {1} | Train Loss: {2:.7f}  Test Loss: {3:.7f} Test Accuracy: {4:.7f}  Test weighted F1: {5:.7f}  Test macro F1 {6:.7f} \".format(\n",
    "        epoch + 1, train_steps, train_loss, test_loss, test_acc, test_f_w, test_f_macro))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27280a",
   "metadata": {},
   "source": [
    "The Evaluation is not standard here. I directly printed the performance of the model on the test set after each epoch training. As you can see, the test accuracy finally converges to about 94. But there are only 8599 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645bd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987eef85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbd027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
