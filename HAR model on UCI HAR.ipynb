{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bc1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169c3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Functions \n",
    "\n",
    "def load_y_data(y_path):\n",
    "    y = np.loadtxt(y_path, dtype=np.int32).reshape(-1,1)\n",
    "    # change labels range from 1-6 t 0-5, this enables a sparse_categorical_crossentropy loss function\n",
    "    return y - 1\n",
    "\n",
    "def load_X_data(X_path):\n",
    "    X_signal_paths = [X_path + file for file in os.listdir(X_path)]\n",
    "    X_signals = [np.loadtxt(path, dtype=np.float32) for path in X_signal_paths]\n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "\n",
    "class data_set(Dataset):\n",
    "    def __init__(self, data_x, data_y):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_x = self.data_x[index]\n",
    "        sample_y = self.data_y[index]\n",
    "        return sample_x, sample_y\n",
    "    \n",
    "\n",
    "def validation(data_loader, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    #model.eval()是保证BN层能够用全部训练数据的均值和方差，\n",
    "    #即测试过程中要保证BN层的均值和方差不变。对于Dropout，model.eval()是利用到了所有网络连接，即不进行随机舍弃神经元。\n",
    "    total_loss = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x,batch_y) in enumerate(data_loader):\n",
    "\n",
    "            batch_x = batch_x.double().to(device)\n",
    "            batch_y = batch_y.long().to(device)\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "\n",
    "            pred = outputs.detach()#.cpu()\n",
    "            true = batch_y.detach()#.cpu()\n",
    "\n",
    "            loss = criterion(pred, true) \n",
    "            total_loss.append(loss.cpu())\n",
    "\n",
    "            preds.extend(list(np.argmax(outputs.detach().cpu().numpy(),axis=1)))\n",
    "            trues.extend(list(batch_y.detach().cpu().numpy()))   \n",
    "\n",
    "    total_loss = np.average(total_loss)\n",
    "    acc = accuracy_score(preds,trues)\n",
    "\n",
    "    f_w = f1_score(trues, preds, average='weighted')\n",
    "    f_macro = f1_score(trues, preds, average='macro')\n",
    "    f_micro = f1_score(trues, preds, average='micro')\n",
    "    model.train()\n",
    "\n",
    "    return total_loss,  acc, f_w,  f_macro, f_micro#, f_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37641f",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d22010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful information:\n",
      "shapes (n_samples, n_steps, n_signals) of X_train: (7352, 128, 9) and X_test: (2947, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "PATH =  \"C:\\\\Users\\\\weizh\\\\桌面\\\\asd\\\\Model\\\\UCI HAR Dataset_2\"\n",
    "LABEL_NAMES = [\"Walking\", \"Walking upstairs\", \"Walking downstairs\", \"Sitting\", \"Standing\", \"Laying\"]\n",
    "\n",
    "# load X data\n",
    "X_train = load_X_data(os.path.join(PATH + r'\\train\\Inertial Signals/'))\n",
    "X_test = load_X_data(os.path.join(PATH + r'\\test\\Inertial Signals/'))\n",
    "# load y label\n",
    "y_train = load_y_data(os.path.join(PATH + r'\\train\\y_train.txt'))\n",
    "y_test = load_y_data(os.path.join(PATH + r'\\test\\y_test.txt'))\n",
    "\n",
    "print(\"useful information:\")\n",
    "print(f\"shapes (n_samples, n_steps, n_signals) of X_train: {X_train.shape} and X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e891582",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde981e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data = data_set(X_train,y_train[:,0])\n",
    "test_data = data_set(X_test,y_test[:,0])\n",
    "\n",
    "train_data_loader = DataLoader(train_data, \n",
    "                               batch_size   =  batch_size,\n",
    "                               shuffle      =  True,\n",
    "                               num_workers  =  0,\n",
    "                               drop_last    =  False)\n",
    "\n",
    "test_data_loader = DataLoader(test_data, \n",
    "                               batch_size   =  batch_size,\n",
    "                               shuffle      =  False,\n",
    "                               num_workers  =  0,\n",
    "                               drop_last    =  False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1f63f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8927e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(ni: int, no: int, ks: int = 1, stride: int = 1, padding: int = 0, bias: bool = False):\n",
    "    \"\"\"\n",
    "    ni: in channel  no: out channel ks:kern size\n",
    "    Create and initialize a `nn.Conv1d` layer with spectral normalization.\n",
    "    \"\"\"\n",
    "    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n",
    "    nn.init.kaiming_normal_(conv.weight)\n",
    "    if bias:\n",
    "        conv.bias.data.zero_()\n",
    "    # return spectral_norm(conv)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75fc9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    # self-attention implementation from https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "    Self attention layer for nd\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels: int, div):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        if n_channels > 1:\n",
    "            self.query = conv1d(n_channels, n_channels//div,bias=True)\n",
    "            self.key = conv1d(n_channels, n_channels//div,bias=True)\n",
    "        else:\n",
    "            self.query = conv1d(n_channels, n_channels,bias=True)\n",
    "            self.key = conv1d(n_channels, n_channels,bias=True)\n",
    "        self.value = conv1d(n_channels, n_channels)\n",
    "        self.gamma = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Notation from https://arxiv.org/pdf/1805.08318.pdf\n",
    "        size = x.size()\n",
    "        #print(\"size+\",size)\n",
    "        x = x.view(*size[:2], -1)\n",
    "        #print(\"size-\",x.size())\n",
    "        f, g, h = self.query(x), self.key(x), self.value(x)\n",
    "\n",
    "        beta = F.softmax(torch.bmm(f.permute(0, 2, 1).contiguous(), g), dim=1)\n",
    "        o = self.gamma * torch.bmm(h, beta) + x\n",
    "        return o.view(*size).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32bf826",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SelfAttention(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa7657d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfAttention(\n",
       "  (query): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "  (key): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "  (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e72e552d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(1,32,9)\n",
    "a(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0ed20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape ,\n",
    "        number_class , \n",
    "        filter_num = 32,\n",
    "        filter_size = 5,\n",
    "        nb_conv_layers = 4,\n",
    "        dropout = 0.2,\n",
    "        activation = \"ReLU\",\n",
    "        sa_div= 1,\n",
    "    ):\n",
    "        super(HARmodel, self).__init__()\n",
    "        \n",
    "        # PART 1 , Channel wise Feature Extraction\n",
    "        \n",
    "        layers_conv = []\n",
    "        for i in range(nb_conv_layers):\n",
    "        \n",
    "            if i == 0:\n",
    "                in_channel = 1\n",
    "            else:\n",
    "                in_channel = filter_num\n",
    "    \n",
    "            layers_conv.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channel, filter_num, (filter_size, 1),(2,1)),#(2,1)\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(filter_num),\n",
    "\n",
    "            ))\n",
    "        \n",
    "        self.layers_conv = nn.ModuleList(layers_conv)\n",
    "\n",
    "        # PART2 , Cross Channel Fusion through Attention\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.sa = SelfAttention(filter_num, sa_div)\n",
    "        \n",
    "        shape = self.get_the_shape(input_shape)\n",
    "\n",
    "        # PART 3 , Prediction \n",
    "        \n",
    "        self.activation = nn.ReLU() \n",
    "        self.fc1 = nn.Linear(input_shape[2]*filter_num ,filter_num)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(shape[1]*filter_num ,filter_num)\n",
    "        self.fc3 = nn.Linear(filter_num ,number_class)\n",
    "\n",
    "\n",
    "        \n",
    "    def get_the_shape(self, input_shape):\n",
    "        x = torch.rand(input_shape)\n",
    "        print('aaaaaaaaaaaa',x.shape)\n",
    "        x = x.unsqueeze(1)\n",
    "        print('bbbbbbbbbbbb',x.shape)\n",
    "        for layer in self.layers_conv:\n",
    "            x = layer(x)  \n",
    "            print(type(x))\n",
    "        atten_x = torch.cat(\n",
    "            [self.sa(torch.unsqueeze(x[:, :, t, :], dim=3)) for t in range(x.shape[2])],\n",
    "            dim=-1,\n",
    "        )\n",
    "        atten_x = atten_x.permute(0, 3, 1, 2)\n",
    "        return atten_x.shape\n",
    "    def refined(self,x):\n",
    "        refined = torch.cat(\n",
    "            [self.sa(torch.unsqueeze(x[:, :, t, :], dim=3)) for t in range(x.shape[2])],\n",
    "            dim=-1,\n",
    "        )\n",
    "        return refined\n",
    "    def forward(self, x):\n",
    "        # B L C\n",
    "        #print(x.shape)\n",
    "        print('输入数据尺寸',x.shape)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        print(type(x))\n",
    "        for layer in self.layers_conv:\n",
    "            x = layer(x)      \n",
    "            print('每一个卷积层输出尺寸',x.shape)\n",
    "        #batch, filter, length, channel = x.shape\n",
    "\n",
    "\n",
    "        # apply self-attention on each temporal dimension (along sensor and feature dimensions)\n",
    "        \n",
    "\n",
    "\n",
    "        #print('app',refined.shape)\n",
    "        x = self.refined(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        print('refined/attention之后的数据尺寸',x.shape)\n",
    "        #print('refined.permute(0, 3, 1, 2)')\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1)\n",
    "        print('reshape之后数据尺寸',x.shape)\n",
    "        x = self.dropout(x)\n",
    "        print('dropout之后数据尺寸',x.shape)\n",
    "        \n",
    "        x = self.activation(self.fc1(x)) # B L C\n",
    "        print('activation之后数据尺寸',x.shape)\n",
    "        x = self.flatten(x)\n",
    "        print('flatten之后的数据尺寸',x.shape)\n",
    "        #print(type(x))\n",
    "        x = self.activation(self.fc2(x)) # B L C\n",
    "        print('再次activation之后的数据尺寸',x.shape)\n",
    "        y = self.fc3(x)    \n",
    "        print('最终输出的数据尺寸',y.shape,'\\n'*2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ef93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_1 = nn.Conv1d(9, 36, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd3e3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 36, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(32,9,128)\n",
    "inp = a_1(inp)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2c01263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, gate = x.chunk(2, dim=self.dim)\n",
    "        return out * gate.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b38c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "glu = GLU(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3287da83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 36, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glu(inp).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988c8bb",
   "metadata": {},
   "source": [
    "# Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9b02249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import tensorwatch as tw\n",
    "import torchvision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e39437a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaa torch.Size([1, 128, 9])\n",
      "bbbbbbbbbbbb torch.Size([1, 1, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "Parameter : 33639\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import time\n",
    "learning_rate = 0.0001\n",
    "train_epochs = 300\n",
    "device = torch.device('cuda:{}'.format(0))\n",
    "criterion =  nn.CrossEntropyLoss(reduction=\"mean\").to(device)\n",
    "\n",
    "\n",
    "#input_shape = (1, length, channel)\n",
    "model = HARmodel((1,128,9),6,filter_num = 32).double().to(device)\n",
    "\n",
    "print(\"Parameter :\", np.sum([para.numel() for para in model.parameters()]))\n",
    "model_optim = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_steps = len(train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ec967",
   "metadata": {},
   "source": [
    "import torch.onnx\n",
    " \n",
    "import netron\n",
    "input_ = torch.randn(128,128,9).to(device=device, dtype=torch.double)\n",
    "out_put = model(input_)\n",
    "print(type(out_put))\n",
    "print(out_put_.shape)\n",
    "onnx_path = \"netForwatch.onnx\"\n",
    "torch.onnx.export(model, input, onnx_path)\n",
    "\n",
    "netron.start(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58137fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([56, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([56, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([56, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([56, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([56, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([56, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([56, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([56, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([56, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([56, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([56, 32])\n",
      "最终输出的数据尺寸 torch.Size([56, 6]) \n",
      "\n",
      "\n",
      "Epoch: 1 cost time: 8.248387098312378\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n",
      "输入数据尺寸 torch.Size([128, 128, 9])\n",
      "<class 'torch.Tensor'>\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 62, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 29, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 13, 9])\n",
      "每一个卷积层输出尺寸 torch.Size([128, 32, 5, 9])\n",
      "refined/attention之后的数据尺寸 torch.Size([128, 5, 32, 9])\n",
      "reshape之后数据尺寸 torch.Size([128, 5, 288])\n",
      "dropout之后数据尺寸 torch.Size([128, 5, 288])\n",
      "activation之后数据尺寸 torch.Size([128, 5, 32])\n",
      "flatten之后的数据尺寸 torch.Size([128, 160])\n",
      "再次activation之后的数据尺寸 torch.Size([128, 32])\n",
      "最终输出的数据尺寸 torch.Size([128, 6]) \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17752/2111423575.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mtest_loss\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_f_w\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtest_f_macro\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtest_f_micro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     print(\"TEST: Epoch: {0}, Steps: {1} | Train Loss: {2:.7f}  Test Loss: {3:.7f} Test Accuracy: {4:.7f}  Test weighted F1: {5:.7f}  Test macro F1 {6:.7f} \".format(\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17752/755688513.py\u001b[0m in \u001b[0;36mvalidation\u001b[1;34m(data_loader, criterion)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(train_epochs):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    epoch_time = time.time()\n",
    "\n",
    "    for i, (batch_x,batch_y) in enumerate(train_data_loader):\n",
    "        #start = time.time()\n",
    "\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "\n",
    "        batch_x = batch_x.double().to(device)\n",
    "        batch_y = batch_y.long().to(device)\n",
    "        \n",
    "        outputs = model(batch_x)\n",
    "        #print(time.time()-start)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "        #print(time.time()-start)\n",
    "        #print(\"-------------\")\n",
    "\n",
    "    print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n",
    "\n",
    "    train_loss = np.average(train_loss)\n",
    "\n",
    "\n",
    "    test_loss , test_acc, test_f_w,  test_f_macro,  test_f_micro = validation(test_data_loader, criterion)\n",
    "\n",
    "    print(\"TEST: Epoch: {0}, Steps: {1} | Train Loss: {2:.7f}  Test Loss: {3:.7f} Test Accuracy: {4:.7f}  Test weighted F1: {5:.7f}  Test macro F1 {6:.7f} \".format(\n",
    "        epoch + 1, train_steps, train_loss, test_loss, test_acc, test_f_w, test_f_macro))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27280a",
   "metadata": {},
   "source": [
    "The Evaluation is not standard here. I directly printed the performance of the model on the test set after each epoch training. As you can see, the test accuracy finally converges to about 94. But there are only 8599 parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
